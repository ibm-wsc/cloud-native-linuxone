{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Cloud Native LinuxONE Workshop \u00b6 Welcome to our Cloud Native LinuxONE workshop. Developers can leverage OpenShift to create continuous integration pipelines for Linux\u00ae workloads on IBM Z\u00ae and LinuxONE. You can quickly get up and running on OpenShift with a continuous workflow. Agenda \u00b6 Introduction to Cloud Native Workshop Deploy Pet Clinic via OpenShift Pipelines Extend Pipeline to Upgrade from Delopment to Staging Acknowledgements \u00b6 Thanks to the following contributors: Chee Yee for setting up the LinuxONE Community Cloud for the OpenShift Pipelines workflow The spring developers for creating the petclinic demo and the redhat-developer-demos for sharing the spring-petclinic version of sample application we started with Workshop owners \u00b6 Barry Silliman Garrett Woodworth Jin VanStee","title":"Home"},{"location":"#cloud-native-linuxone-workshop","text":"Welcome to our Cloud Native LinuxONE workshop. Developers can leverage OpenShift to create continuous integration pipelines for Linux\u00ae workloads on IBM Z\u00ae and LinuxONE. You can quickly get up and running on OpenShift with a continuous workflow.","title":"Cloud Native LinuxONE Workshop"},{"location":"#agenda","text":"Introduction to Cloud Native Workshop Deploy Pet Clinic via OpenShift Pipelines Extend Pipeline to Upgrade from Delopment to Staging","title":"Agenda"},{"location":"#acknowledgements","text":"Thanks to the following contributors: Chee Yee for setting up the LinuxONE Community Cloud for the OpenShift Pipelines workflow The spring developers for creating the petclinic demo and the redhat-developer-demos for sharing the spring-petclinic version of sample application we started with","title":"Acknowledgements"},{"location":"#workshop-owners","text":"Barry Silliman Garrett Woodworth Jin VanStee","title":"Workshop owners"},{"location":"glossary/","text":"OCP / OpenShift Container Platform: a platform as a service using containers maintained and distributed by Red Hat from the open source offering Origin using Kubernetes as the underlying container orchestration software. Kubernetes (k8s): an open source, extensible container orchestrator Container image: a linux application image built as a static starting point for use with a container","title":"Glossary of terms"},{"location":"introduction/","text":"Cloud Native Workshop Introduction \u00b6 We will setup and deploy an application (the cloud-native way) using OpenShift Container Platform and it's CI/CD workflow Openshift Pipelines. Overall Architecture Image \u00b6 One day an architecture image will sit here. Until then, enjoy this text. Lab Overview \u00b6 You will set up a virtual pet clinic (based on the classic spring boot demo referenced in the main documentation running on LinuxONE using source code on GitHub and OpenShift Pipelines to seamlessly update, test, and deploy your clinic. This lab is broken into two parts: Automating build and deploy of PetClinic Java application with OpenShift Pipelines Promoting PetClinic from development to staging with GitHub integration","title":"Introduction"},{"location":"introduction/#cloud-native-workshop-introduction","text":"We will setup and deploy an application (the cloud-native way) using OpenShift Container Platform and it's CI/CD workflow Openshift Pipelines.","title":"Cloud Native Workshop Introduction"},{"location":"introduction/#overall-architecture-image","text":"One day an architecture image will sit here. Until then, enjoy this text.","title":"Overall Architecture Image"},{"location":"introduction/#lab-overview","text":"You will set up a virtual pet clinic (based on the classic spring boot demo referenced in the main documentation running on LinuxONE using source code on GitHub and OpenShift Pipelines to seamlessly update, test, and deploy your clinic. This lab is broken into two parts: Automating build and deploy of PetClinic Java application with OpenShift Pipelines Promoting PetClinic from development to staging with GitHub integration","title":"Lab Overview"},{"location":"prerequisites/","text":"Prerequisites \u00b6 Create a GitHub \u00b6 Create a GitHub account (if you don't already have one) here . Create a LinuxONE Community Cloud OpenShift Container Platform Trial \u00b6 Create a LinuxONE Community Cloud OpenShift Container Platform trial here .","title":"Prerequisites"},{"location":"prerequisites/#prerequisites","text":"","title":"Prerequisites"},{"location":"prerequisites/#create-a-github","text":"Create a GitHub account (if you don't already have one) here .","title":"Create a GitHub"},{"location":"prerequisites/#create-a-linuxone-community-cloud-openshift-container-platform-trial","text":"Create a LinuxONE Community Cloud OpenShift Container Platform trial here .","title":"Create a LinuxONE Community Cloud OpenShift Container Platform Trial"},{"location":"proposechange/","text":"How to propose a change \u00b6 On the page you want to make a change to, click on the pencil icon next to the page's title. This will take you to edit the page in Github. You will see a message similar to the following: \"You\u2019re editing a file in a project you don\u2019t have write access to. Submitting a change to this file will write it to a new branch in your fork, so you can send a pull request.\" Make your changes in Markdown. And submit for review. The owners of this repo will review your pull request and accept or deny your change proposal. There are other ways of doing a pull request, a Google search will lead you to those tutorials.","title":"Propose a change"},{"location":"proposechange/#how-to-propose-a-change","text":"On the page you want to make a change to, click on the pencil icon next to the page's title. This will take you to edit the page in Github. You will see a message similar to the following: \"You\u2019re editing a file in a project you don\u2019t have write access to. Submitting a change to this file will write it to a new branch in your fork, so you can send a pull request.\" Make your changes in Markdown. And submit for review. The owners of this repo will review your pull request and accept or deny your change proposal. There are other ways of doing a pull request, a Google search will lead you to those tutorials.","title":"How to propose a change"},{"location":"resources/","text":"Other Resources \u00b6 OpenShift Pipelines Resources \u00b6 Information Page Intro Series on OpenShift blog","title":"Other resources"},{"location":"resources/#other-resources","text":"","title":"Other Resources"},{"location":"resources/#openshift-pipelines-resources","text":"Information Page Intro Series on OpenShift blog","title":"OpenShift Pipelines Resources"},{"location":"application-promotion/action/","text":"Time to put it all in action for take 2 \u00b6","title":"Full pipeline in Action"},{"location":"application-promotion/action/#time-to-put-it-all-in-action-for-take-2","text":"","title":"Time to put it all in action for take 2"},{"location":"application-promotion/overview/","text":"It's time to get your pet clinic ready for its internal dayview \u00b6 In this section, you will bring PetClinic from development to staging for the internal showcase opening of your pet clinic (staging). Promotion Tasks Check rollout of PetClinic dev version Deploy PetClinic staging version Check rollout of PetClinic staging version Git Tasks Add GitHub trigger to pipeline Pass Git commit messages and hashes to pipeline Version images by git commit Add webhook to GitHub so it will trigger a new PipelineRun for each push Running Pipeline Update PetClinic with new animal and push to GitHub Watch GitHub trigger PipelineRun Watch app move from staging to dev seamlessly with images tagged with git commit SHA Discuss ways to integrate OpenShift on LinuxONE as part of a greater multi-cloud ecosystem","title":"Section Overview"},{"location":"application-promotion/overview/#its-time-to-get-your-pet-clinic-ready-for-its-internal-dayview","text":"In this section, you will bring PetClinic from development to staging for the internal showcase opening of your pet clinic (staging). Promotion Tasks Check rollout of PetClinic dev version Deploy PetClinic staging version Check rollout of PetClinic staging version Git Tasks Add GitHub trigger to pipeline Pass Git commit messages and hashes to pipeline Version images by git commit Add webhook to GitHub so it will trigger a new PipelineRun for each push Running Pipeline Update PetClinic with new animal and push to GitHub Watch GitHub trigger PipelineRun Watch app move from staging to dev seamlessly with images tagged with git commit SHA Discuss ways to integrate OpenShift on LinuxONE as part of a greater multi-cloud ecosystem","title":"It's time to get your pet clinic ready for its internal dayview"},{"location":"application-promotion/promote/","text":"App Promotion Time \u00b6","title":"Promoting Application"},{"location":"application-promotion/promote/#app-promotion-time","text":"","title":"App Promotion Time"},{"location":"build-and-deploy/overview/","text":"It's time to open up your pet clinic for testing \u00b6 In this section, we will build, test and deploy the Java web application for our pet clinic (PetClinic) and then automate the process using OpenShift Pipelines. This involves the following tasks: Get Your Pet Clinic Up and Running on OpenShift Deploying MySQL database Building PetClinic with automated testing Accessing PetClinic and adding an owner Create Your PetClinic Continuous Integration/Continuous Deployment Flow using OpenShift Pipelines Automate MySQL deployment using OpenShift template Make clean image from S2I build Manage PetClinic deployment resources across dev and staging using KUSTOMIZE Setup PetClinic image deployment automation with tagging based on source","title":"Section Overview"},{"location":"build-and-deploy/overview/#its-time-to-open-up-your-pet-clinic-for-testing","text":"In this section, we will build, test and deploy the Java web application for our pet clinic (PetClinic) and then automate the process using OpenShift Pipelines. This involves the following tasks: Get Your Pet Clinic Up and Running on OpenShift Deploying MySQL database Building PetClinic with automated testing Accessing PetClinic and adding an owner Create Your PetClinic Continuous Integration/Continuous Deployment Flow using OpenShift Pipelines Automate MySQL deployment using OpenShift template Make clean image from S2I build Manage PetClinic deployment resources across dev and staging using KUSTOMIZE Setup PetClinic image deployment automation with tagging based on source","title":"It's time to open up your pet clinic for testing"},{"location":"build-and-deploy/pipeline/","text":"PetClinic + OpenShift Pipelines = CI \u00b6 Now that PetClinic is up and running on our OpenShift cluster, it's time to add functionality to our pipeline to achieve basic continuous integration. The OpenShift pipeline we created in the PetClinic Up and Running uses Tekton to run a series of tasks (each with one or more steps) to accomplish a workflow (pipeline). We will use the Pipeline Builder UI built into OpenShift to quickly and easily craft a pipeline for our project. Why OpenShift Pipelines? Portable: OpenShift resources defined via yaml files -> portable across OpenShift clusters Low Resource Usage: Containers spin up when triggered -> resources only used when needed Configurable: Can tailor overall pipeline and individual tasks to needs of your enterprise/organization Ease of Use: Pipeline Builder UI and built-in cluster resources (i.e. ClusterTasks , ClusterTriggerBindings`, etc.) enable you to easily create a pipeline and export the yaml files with minimal knowledge PetClinic Pipeline \u00b6 When we deployed the PetClinic application using the From Git option in the PetClinic Up and Running section, we chose to create a basic pipeline. We'll start with this pipeline and edit it to add new functionality for our use case. Navigate to the Pipelines tab in the Developer perspective on the left and then click the three dots to the right of the pipeline name ( spring-petclinic ) and choose Edit Pipeline . Ensure MySQL Database Deployed for each Run \u00b6 This will bring us to the Pipeline Builder UI where we can edit our pipeline. Here we will make sure the MySQL database is configured according to our specification before the build task. Add a mysql-deploy task in parallel to the git-fetch task. Why MySQL Parallel? This ensures MySQL is in place for each PetClinic application build (which would fail without it). Click on the middle of the bubble of the new task and choose the openshift-client task from the dropdown menu. Enter the following command into the script field to ensure the MySQL database is available with the necessary configuration: oc process openshift//mysql-ephemeral -p MYSQL_USER = petclinic -p MYSQL_PASSWORD = petclinic -p MYSQL_ROOT_PASSWORD = petclinic -p MYSQL_DATABASE = petclinic | oc apply -f - Simply Click Away Once you have entered the string into the SCRIPT section, just click away (i.e. on a regular section of the page) to get the configuration menu to go away and keep the new value(s) you just entered for the task. What is oc process doing? oc process is processing the OpenShift template for the mysql-ephemeral database with the parameters given via a series of -p arguments and finally oc apply -f - ensures that any missing components will be recreated. No help please! Make sure help is deleted from the ARGS section (it will be greyed out once deleted) or bad things will happen (i.e. the help screen will come up instead of the proper command running). Add a mysql-rollout-wait task We need to make sure that mysql is not only on its way to deploying but actually deployed before our build task begins. In order to achieve this, we will use the OpenShift Client again and wait for the rollout of the mysql deploymentConfig to complete after the mysql-deploy task. Add a sequential task after mysql-deploy : Fill out the task with the following parameters: No help please! Make sure help is deleted from the ARGS section (it will be greyed out once deleted) or bad things will happen (i.e. the help screen will come up instead of the proper command running). What the ARGS? You may be wondering why we used the SCRIPT section in the mysql-deploy task for the entire command, but now are using the ARGS to individually list each argument of the command? Both work and so we are going through both methods here. On the one hand, the SCRIPT method is easier to copy and paste and looks the same as it would entered on the command line. On the other hand, the ARGS method adds readability to the task. Choose whichever method you prefer, though beware of input errors with the ARGS method for long commands. FYI: The equivalent SCRIPT command for the mysql-rollout-wait task is : oc rollout status dc/mysql Now our build step will have MySQL alive and well for it to use during the build step as required! Make Clean Image from S2I build \u00b6 The s2i-java-11 image is very convenient for making an image from source code. However, the simplicity that gives it value, can make it fail at meeting the needs of many organizations by itself. In our case, we will take the artifacts from the s2i image and copy them to a new Docker image that can meet all our needs to get the best of both worlds. We'll create an optimized image starting from a compact openj9 java 11 base and employing the advanced layers feature in spring that optimizes Docker image caching with the final-Dockerfile in the ibm-wsc/spring-petclinic git repository we forked. Add Buildah task Add the buildah task as a sequential task after the build task. Configure buildah task Tip Each value that we need to configure is listed below with the value in a click-to-copy window (other values can be left alone to match image) DISPLAY NAME: producing-clean-image IMAGE: $(params.FINAL_IMAGE):$(params.COMMIT_SHA) DOCKERFILE: ./final-Dockerfile TLSVERIFY: false BUILD_EXTRA_ARGS: --build-arg PETCLINIC_S2I_IMAGE=$(params.IMAGE_NAME) Add FINAL_IMAGE , GIT_MESSAGE , and COMMIT_SHA parameters to the pipeline FINAL_IMAGE FINAL_IMAGE Parameter Name: FINAL_IMAGE FINAL_IMAGE Parameter Description: Image Repository for Final Image FINAL_IMAGE Parameter Default Value: image-registry.openshift-image-registry.svc:5000/1619589196769/spring-petclinic-git-minimal GIT_MESSAGE GIT_MESSAGE Parameter Name: GIT_MESSAGE GIT_MESSAGE Parameter Description: Git commit message if triggered by Git, otherwise it's a manual build GIT_MESSAGE Parameter Default Value This is a manual build (not triggered by Git) COMMIT_SHA COMMIT_SHA Parameter Name: COMMIT_SHA COMMIT_SHA Parameter Description: SHA of Git commit if triggered by Git, otherwise just update manual tag COMMIT_SHA Parameter Default Value: latest Tip Save parameters when done with entry before moving onto step 4. Add workspace to producing-clean-image task Save current pipeline edit and switch to yaml from pipeline menu. Why are we editing yaml directly? Workspaces are more versatile than traditional PipelineResources which is why we are using them. However, as the transition to workspaces continues, the OpenShift Pipeline Builder doesn't support editing the Workspace mapping from a pipeline to a task via the Builder UI so we have to do it directly in the yaml for now. Find the producing-clean-image-task and add the following workspace definition: workspaces: - name: source workspace: workspace Save the update Note After the save message above appears you can then proceed to Cancel back to the pipeline menu. Manage resource across environments with Kustomize \u00b6 Kustomize is a tool for customizing Kubernetes resource configuration. From the documentation overview Kustomize traverses a Kubernetes manifest to add, remove or update configuration options without forking. It is available both as a standalone binary and as a native feature of kubectl. As part of doing things the \"cloud-native way\", we will be using Kustomize to manage resource changes across our dev and staging environments as well as injecting information from our pipeline (such as newly created image information with git commits) into our Kubernetes (OpenShift) resources. See our Kustomize configuration in our GitHub code in the subdirectories of the ocp-files directory See the kubectl documentation for more information about how to use Kustomize via kubectl / oc. Creating Custom Task for Kustomize \u00b6 Since there is no ClusterTask defined for Kustomize, we will create a custom task for this purpose. It will change into the Kustomize directory, run a Kustomize command on the directory, and then apply the files from the directory using the built-in Kustomize functionality of the oc command line tool (via kubectl's Kustomize support) Copy the kustomize-deploy-resources Task using the following definition (copy by clicking on the copy icon in the top right of the box below): apiVersion: tekton.dev/v1beta1 kind: Task metadata: name: kustomize-deploy-resources spec: description: >- This task runs commands against the cluster where the task run is being executed. Kustomize is a tool for Kubernetes native configuration management. It introduces a template-free way to customize application configuration that simplifies the use of off-the-shelf applications. Now, built into kubectl as apply -k and oc as oc apply -k. params: - default: /workspace/source/ocp-files description: The directory where the kustomization yaml file ( s ) reside name: KUSTOMIZE_DIR type: string - default: base description: subdirectory of KUSTOMIZE_DIR used for extra configuration of current resources name: EDIT_SUDBDIR type: string - default: overlay/dev description: subdirectory of KUSTOMIZE_DIR used for specifying resources for a specific release such as dev or staging name: RELEASE_SUBDIR type: string - default: kustomize edit set image $( params.APP_NAME ) = $( params.FINAL_IMAGE ) : $( params.COMMIT_SHA ) description: The Kustomize CLI arguments to run name: SCRIPT type: string steps: - image: 'docker.io/gmoney23/kustomize-s390x:v4.1.2' name: kustomize resources: limits: cpu: 200m memory: 200Mi requests: cpu: 200m memory: 200Mi script: cd $( params.KUSTOMIZE_DIR ) / $( params.EDIT_SUDBDIR ) && $( params.SCRIPT ) - image: 'image-registry.openshift-image-registry.svc:5000/openshift/cli:latest' name: apply-oc-files resources: limits: cpu: 200m memory: 200Mi requests: cpu: 200m memory: 200Mi script: oc apply -k $( params.KUSTOMIZE_DIR ) / $( params.RELEASE_SUBDIR ) workspaces: - name: source description: The git source code Create the kustomize-deploy-resources Task a. Click Import YAML to bring up the box where you can create Kubernetes resource definitions from yaml b. Paste the kustomize-deploy-resources Task into the box c. Scroll down and click create to create the kustomize-deploy-resources Task You should now see the created kustomize-deploy-resources Task and navigate back to the Pipelines section of OpenShift and go back to editing your pipeline. Add Kustomize Task to Pipeline \u00b6 Find kustomize-deploy-resources and add it to your pipeline after producing-clean-image Configure kustomize-deploy-resources task Since environment is dev for initial deploy, we can use all of the default values and change the Display Name to kustomize-deploy-resources-dev . Add workspace to kustomize-deploy-resources task Save current pipeline edit and switch to yaml from pipeline menu. Why are we editing yaml directly? Workspaces are more versatile than traditional PipelineResources which is why we are using them. However, as the transition to workspaces continues, the OpenShift Pipeline Builder doesn't support editing the Workspace mapping from a pipeline to a task via the Builder UI so we have to do it directly in the yaml for now. Find the kustomize-deploy-resources and add the following workspace definition: workspaces: - name: source workspace: workspace Save the update Note After the save message above appears you can then proceed to Cancel back to the pipeline menu. Clean Old PetClinic Instances at the Beginning of a Run \u00b6 Add an task named cleanup-resources sequentially at the beginning of the pipeline before fetch-repository (using the openshift-client ClusterTask). Configure the task with a SCRIPT value of: oc delete deployment,svc,route -l app = $( params.APP_NAME ) --ignore-not-found and an empty ARGS value. No help please! Make sure help is deleted from the ARGS section (it will be greyed out once deleted) or bad things will happen (i.e. the help screen will come up instead of the proper command running). Update Deploy Task to deploy-dev \u00b6 Change the name of the task at the end of the pipeline to deploy-dev and change the last ARG from deploy/$(params.APP_NAME) to: deploy/ $( params.APP_NAME ) -dev Save your pipeline! Run the Updated Pipeline \u00b6 Go to Actions -> Start in the right hand corner of the pipeline menu Manually trigger a PipelineRun by accepting the default values and clicking on Start . Persistent Volume Claim Note Please select a PersistentVolumeClaim if it is not already filled out for you to complete your pipeline. If it is already filled out for you then jump right to starting the pipeline. Watch the results of your build. It should run successfully as in the pictures below. PipelineRun Success View Perspective: PipelineRun Success Logs Perspective:","title":"PetClinic + OpenShift Pipelines = CI"},{"location":"build-and-deploy/pipeline/#petclinic-openshift-pipelines-ci","text":"Now that PetClinic is up and running on our OpenShift cluster, it's time to add functionality to our pipeline to achieve basic continuous integration. The OpenShift pipeline we created in the PetClinic Up and Running uses Tekton to run a series of tasks (each with one or more steps) to accomplish a workflow (pipeline). We will use the Pipeline Builder UI built into OpenShift to quickly and easily craft a pipeline for our project. Why OpenShift Pipelines? Portable: OpenShift resources defined via yaml files -> portable across OpenShift clusters Low Resource Usage: Containers spin up when triggered -> resources only used when needed Configurable: Can tailor overall pipeline and individual tasks to needs of your enterprise/organization Ease of Use: Pipeline Builder UI and built-in cluster resources (i.e. ClusterTasks , ClusterTriggerBindings`, etc.) enable you to easily create a pipeline and export the yaml files with minimal knowledge","title":"PetClinic + OpenShift Pipelines = CI"},{"location":"build-and-deploy/pipeline/#petclinic-pipeline","text":"When we deployed the PetClinic application using the From Git option in the PetClinic Up and Running section, we chose to create a basic pipeline. We'll start with this pipeline and edit it to add new functionality for our use case. Navigate to the Pipelines tab in the Developer perspective on the left and then click the three dots to the right of the pipeline name ( spring-petclinic ) and choose Edit Pipeline .","title":"PetClinic Pipeline"},{"location":"build-and-deploy/pipeline/#ensure-mysql-database-deployed-for-each-run","text":"This will bring us to the Pipeline Builder UI where we can edit our pipeline. Here we will make sure the MySQL database is configured according to our specification before the build task. Add a mysql-deploy task in parallel to the git-fetch task. Why MySQL Parallel? This ensures MySQL is in place for each PetClinic application build (which would fail without it). Click on the middle of the bubble of the new task and choose the openshift-client task from the dropdown menu. Enter the following command into the script field to ensure the MySQL database is available with the necessary configuration: oc process openshift//mysql-ephemeral -p MYSQL_USER = petclinic -p MYSQL_PASSWORD = petclinic -p MYSQL_ROOT_PASSWORD = petclinic -p MYSQL_DATABASE = petclinic | oc apply -f - Simply Click Away Once you have entered the string into the SCRIPT section, just click away (i.e. on a regular section of the page) to get the configuration menu to go away and keep the new value(s) you just entered for the task. What is oc process doing? oc process is processing the OpenShift template for the mysql-ephemeral database with the parameters given via a series of -p arguments and finally oc apply -f - ensures that any missing components will be recreated. No help please! Make sure help is deleted from the ARGS section (it will be greyed out once deleted) or bad things will happen (i.e. the help screen will come up instead of the proper command running). Add a mysql-rollout-wait task We need to make sure that mysql is not only on its way to deploying but actually deployed before our build task begins. In order to achieve this, we will use the OpenShift Client again and wait for the rollout of the mysql deploymentConfig to complete after the mysql-deploy task. Add a sequential task after mysql-deploy : Fill out the task with the following parameters: No help please! Make sure help is deleted from the ARGS section (it will be greyed out once deleted) or bad things will happen (i.e. the help screen will come up instead of the proper command running). What the ARGS? You may be wondering why we used the SCRIPT section in the mysql-deploy task for the entire command, but now are using the ARGS to individually list each argument of the command? Both work and so we are going through both methods here. On the one hand, the SCRIPT method is easier to copy and paste and looks the same as it would entered on the command line. On the other hand, the ARGS method adds readability to the task. Choose whichever method you prefer, though beware of input errors with the ARGS method for long commands. FYI: The equivalent SCRIPT command for the mysql-rollout-wait task is : oc rollout status dc/mysql Now our build step will have MySQL alive and well for it to use during the build step as required!","title":"Ensure MySQL Database Deployed for each Run"},{"location":"build-and-deploy/pipeline/#make-clean-image-from-s2i-build","text":"The s2i-java-11 image is very convenient for making an image from source code. However, the simplicity that gives it value, can make it fail at meeting the needs of many organizations by itself. In our case, we will take the artifacts from the s2i image and copy them to a new Docker image that can meet all our needs to get the best of both worlds. We'll create an optimized image starting from a compact openj9 java 11 base and employing the advanced layers feature in spring that optimizes Docker image caching with the final-Dockerfile in the ibm-wsc/spring-petclinic git repository we forked. Add Buildah task Add the buildah task as a sequential task after the build task. Configure buildah task Tip Each value that we need to configure is listed below with the value in a click-to-copy window (other values can be left alone to match image) DISPLAY NAME: producing-clean-image IMAGE: $(params.FINAL_IMAGE):$(params.COMMIT_SHA) DOCKERFILE: ./final-Dockerfile TLSVERIFY: false BUILD_EXTRA_ARGS: --build-arg PETCLINIC_S2I_IMAGE=$(params.IMAGE_NAME) Add FINAL_IMAGE , GIT_MESSAGE , and COMMIT_SHA parameters to the pipeline FINAL_IMAGE FINAL_IMAGE Parameter Name: FINAL_IMAGE FINAL_IMAGE Parameter Description: Image Repository for Final Image FINAL_IMAGE Parameter Default Value: image-registry.openshift-image-registry.svc:5000/1619589196769/spring-petclinic-git-minimal GIT_MESSAGE GIT_MESSAGE Parameter Name: GIT_MESSAGE GIT_MESSAGE Parameter Description: Git commit message if triggered by Git, otherwise it's a manual build GIT_MESSAGE Parameter Default Value This is a manual build (not triggered by Git) COMMIT_SHA COMMIT_SHA Parameter Name: COMMIT_SHA COMMIT_SHA Parameter Description: SHA of Git commit if triggered by Git, otherwise just update manual tag COMMIT_SHA Parameter Default Value: latest Tip Save parameters when done with entry before moving onto step 4. Add workspace to producing-clean-image task Save current pipeline edit and switch to yaml from pipeline menu. Why are we editing yaml directly? Workspaces are more versatile than traditional PipelineResources which is why we are using them. However, as the transition to workspaces continues, the OpenShift Pipeline Builder doesn't support editing the Workspace mapping from a pipeline to a task via the Builder UI so we have to do it directly in the yaml for now. Find the producing-clean-image-task and add the following workspace definition: workspaces: - name: source workspace: workspace Save the update Note After the save message above appears you can then proceed to Cancel back to the pipeline menu.","title":"Make Clean Image from S2I build"},{"location":"build-and-deploy/pipeline/#manage-resource-across-environments-with-kustomize","text":"Kustomize is a tool for customizing Kubernetes resource configuration. From the documentation overview Kustomize traverses a Kubernetes manifest to add, remove or update configuration options without forking. It is available both as a standalone binary and as a native feature of kubectl. As part of doing things the \"cloud-native way\", we will be using Kustomize to manage resource changes across our dev and staging environments as well as injecting information from our pipeline (such as newly created image information with git commits) into our Kubernetes (OpenShift) resources. See our Kustomize configuration in our GitHub code in the subdirectories of the ocp-files directory See the kubectl documentation for more information about how to use Kustomize via kubectl / oc.","title":"Manage resource across environments with Kustomize"},{"location":"build-and-deploy/pipeline/#creating-custom-task-for-kustomize","text":"Since there is no ClusterTask defined for Kustomize, we will create a custom task for this purpose. It will change into the Kustomize directory, run a Kustomize command on the directory, and then apply the files from the directory using the built-in Kustomize functionality of the oc command line tool (via kubectl's Kustomize support) Copy the kustomize-deploy-resources Task using the following definition (copy by clicking on the copy icon in the top right of the box below): apiVersion: tekton.dev/v1beta1 kind: Task metadata: name: kustomize-deploy-resources spec: description: >- This task runs commands against the cluster where the task run is being executed. Kustomize is a tool for Kubernetes native configuration management. It introduces a template-free way to customize application configuration that simplifies the use of off-the-shelf applications. Now, built into kubectl as apply -k and oc as oc apply -k. params: - default: /workspace/source/ocp-files description: The directory where the kustomization yaml file ( s ) reside name: KUSTOMIZE_DIR type: string - default: base description: subdirectory of KUSTOMIZE_DIR used for extra configuration of current resources name: EDIT_SUDBDIR type: string - default: overlay/dev description: subdirectory of KUSTOMIZE_DIR used for specifying resources for a specific release such as dev or staging name: RELEASE_SUBDIR type: string - default: kustomize edit set image $( params.APP_NAME ) = $( params.FINAL_IMAGE ) : $( params.COMMIT_SHA ) description: The Kustomize CLI arguments to run name: SCRIPT type: string steps: - image: 'docker.io/gmoney23/kustomize-s390x:v4.1.2' name: kustomize resources: limits: cpu: 200m memory: 200Mi requests: cpu: 200m memory: 200Mi script: cd $( params.KUSTOMIZE_DIR ) / $( params.EDIT_SUDBDIR ) && $( params.SCRIPT ) - image: 'image-registry.openshift-image-registry.svc:5000/openshift/cli:latest' name: apply-oc-files resources: limits: cpu: 200m memory: 200Mi requests: cpu: 200m memory: 200Mi script: oc apply -k $( params.KUSTOMIZE_DIR ) / $( params.RELEASE_SUBDIR ) workspaces: - name: source description: The git source code Create the kustomize-deploy-resources Task a. Click Import YAML to bring up the box where you can create Kubernetes resource definitions from yaml b. Paste the kustomize-deploy-resources Task into the box c. Scroll down and click create to create the kustomize-deploy-resources Task You should now see the created kustomize-deploy-resources Task and navigate back to the Pipelines section of OpenShift and go back to editing your pipeline.","title":"Creating Custom Task for Kustomize"},{"location":"build-and-deploy/pipeline/#add-kustomize-task-to-pipeline","text":"Find kustomize-deploy-resources and add it to your pipeline after producing-clean-image Configure kustomize-deploy-resources task Since environment is dev for initial deploy, we can use all of the default values and change the Display Name to kustomize-deploy-resources-dev . Add workspace to kustomize-deploy-resources task Save current pipeline edit and switch to yaml from pipeline menu. Why are we editing yaml directly? Workspaces are more versatile than traditional PipelineResources which is why we are using them. However, as the transition to workspaces continues, the OpenShift Pipeline Builder doesn't support editing the Workspace mapping from a pipeline to a task via the Builder UI so we have to do it directly in the yaml for now. Find the kustomize-deploy-resources and add the following workspace definition: workspaces: - name: source workspace: workspace Save the update Note After the save message above appears you can then proceed to Cancel back to the pipeline menu.","title":"Add Kustomize Task to Pipeline"},{"location":"build-and-deploy/pipeline/#clean-old-petclinic-instances-at-the-beginning-of-a-run","text":"Add an task named cleanup-resources sequentially at the beginning of the pipeline before fetch-repository (using the openshift-client ClusterTask). Configure the task with a SCRIPT value of: oc delete deployment,svc,route -l app = $( params.APP_NAME ) --ignore-not-found and an empty ARGS value. No help please! Make sure help is deleted from the ARGS section (it will be greyed out once deleted) or bad things will happen (i.e. the help screen will come up instead of the proper command running).","title":"Clean Old PetClinic Instances at the Beginning of a Run"},{"location":"build-and-deploy/pipeline/#update-deploy-task-to-deploy-dev","text":"Change the name of the task at the end of the pipeline to deploy-dev and change the last ARG from deploy/$(params.APP_NAME) to: deploy/ $( params.APP_NAME ) -dev Save your pipeline!","title":"Update Deploy Task to deploy-dev"},{"location":"build-and-deploy/pipeline/#run-the-updated-pipeline","text":"Go to Actions -> Start in the right hand corner of the pipeline menu Manually trigger a PipelineRun by accepting the default values and clicking on Start . Persistent Volume Claim Note Please select a PersistentVolumeClaim if it is not already filled out for you to complete your pipeline. If it is already filled out for you then jump right to starting the pipeline. Watch the results of your build. It should run successfully as in the pictures below. PipelineRun Success View Perspective: PipelineRun Success Logs Perspective:","title":"Run the Updated Pipeline"},{"location":"build-and-deploy/upandrunning/","text":"Getting Your PetClinic Up and Running \u00b6 For this workshop we will be using the iconic Spring PetClinic application. The Spring PetClinic is a sample application designed to show how the Spring stack can be used to build simple, but powerful database-oriented applications. The official version of PetClinic demonstrates the use of Spring Boot with Spring MVC and Spring Data JPA. We will not be focusing on the ins and outs of the PetClinic application itself, but rather on leveraging OpenShift tooling to build a PetClinic cloud-native application and a DevOps pipeline for the application. We will start by building our PetClinic application from the source code and connecting it to a MySQL database. Using LinuxONE Community Cloud Because you are using the LinuxONE Community Cloud OpenShift trial, your project name will be different from the project name depicted in the diagrams below. You will be operating in your assigned project for the entirety of the lab. Lab Guide For the images in this lab: - the green arrows or boxes denote something to look at or reference - the red arrows or boxes denote something to click on or type. Deploying MySQL database \u00b6 1. First, we need to setup our mysql database. Luckily, this is very easy on OpenShift with the mysql template available from the main developer topology window. Follow the steps in the diagram below to bring up the available database options. (Note your project name will be different than the picture below) 2. Next, select the MySQL (Ephemeral) tile. Note we are choosing the ephemeral option because at this point we do not care to persist the database beyond the life of the container. 3. Click on instantiate template. 4. Fill the wizard with the parameters as shown in the image below (your namespace will be different from the image below): Click the Create button. Why Ephemeral? We are using the Ephemeral implementation because this a short-lived demo and we do not need to retain the data. In a staging or production environment, you will most likely be using a MySQL deployment backed by a Persistent Volume Claim. This stores the data in a Persistent Volume (basically a virtual hard drive), and the data will persist beyond the life of the container. A minute or two later, in the Topology view of your OpenShift Console, you should see mysql in running state. (Click on the Topology icon for mysql to bring up the side panel) Fork the PetClinic repo to your own GitHub account \u00b6 For this workshop, you will be using the PetClinic application from your own GitHub account so that you can enable integrations with it later. To make a copy of the PetClinic application into your GitHub account, navigate to the following from your browser: https://github.com/ibm-wsc/spring-petclinic Then click on the fork button on the upper right corner. At this point you might need to log into GitHub if you weren't logged in already. Next, you might be presented with a screen to ask you to select where to fork to. Select your own user account to fork to. Please make a note of your repo URL for later. It should be something like: https://github.com/<your-github-username>/spring-petclinic That's it! You are ready to move on to the next section. Building and Deploying PetClinic Application \u00b6 There are multiple ways OpenShift enables cloud-native application developers to package up their applications and deploy them. For PetClinic, we will be building our application image from source, leveraging OpenShift's S2I (Source to Image) capability. This allows us to quickly test the building, packaging, and deployment of our application, and gives us the option to create and use a DevOps pipeline from this workflow. It's a good way to start to understand how OpenShift Pipelines work. 1. Start with choosing Add From Git: 2. Enter https://github.com/<your-github-ID>/spring-petclinic in the Git Repo URL field. Expand the Show Advanced Git Options section, and type in main for the Git Reference . This tells OpenShift which GitHub repo and branch to pull the source code from. 3. Scroll down to the Builder section. Select the OpenJ9 tile and select openj9-11-el8 as the builder image version. As you can see OpenShift offers many different builder images to help you build images from a variety of programming languages. Your list of builder images might differ from the screen shot. For Java on Z, the recommended JVM is OpenJ9 because it has built-in s390x optimizations as well as container optimizations. 4. In the General section, put in the following entries for Application Name and Name. 5. Scroll down to the Pipelines section, and check off the box next to Add pipeline . You can also expand the Show pipeline visualization section to see a visual of the build pipeline. 6. We are almost there! We will need to configure a couple of Advanced Options. First, click on Routing in the Advanced Options section to expand the Routing options. 7. In the Routing options section, only fill out the Security options as follows. You can leave the rest alone. These options will enable only TLS access to your PetClinic application. 8. You are done with configurations of this panel. Scroll all the way down and hit the Create button which will kick off the pipeline build of your PetClinic application. In a few seconds you will see your Topology with the new application icon. Hit the little pipeline icon in the diagram below to view the build logs. Log Streaming Gotcha in the LinuxONE CC PLEASE BEWARE that if you are using the LinuxONE Community Cloud OpenShift Trial you might see lagginess with the log streaming. If it stops streaming you might want to go back out to the Topology view and once the pipeline completes, come back to the log view to see the logs. 9. The pipeline will go through three tasks: 1. fetch-repository - this Pipeline task will clone your Git PetClinic repo for the build task. 2. build - this Pipeline task is the build process which itself is broken down into a few sub-steps. This is the longest task in the pipeline, and can take up to 15 minutes. The steps that it goes through are as follows: build steps STEP-GEN-ENV-FILE: this step generates the environment file to be used during the build process STEP-GENERATE: this step generates the Dockerfile that will be used to create the OCI image later on during the build step STEP-BUILD: this is the multi-step build process of creating an OCI image out of your Java application PetClinic. It will download the required Maven Java packages, compile the Java application, run through a set of 39 unit tests on the application, and finally build the application jar file and the OCI image. If the tests fail, this step will not complete. STEP-PUSH: this final step pushes the built OCI image to the OpenShift image registry. 3. deploy - this Pipeline task will deploy the newly built image as a running deployment in your project. After this, your application will be running in a pod and be accessible via a route. Below is an image of the log of a successful build task: 10. Now if you go back to the Topology view, you should see the application has been successfully deployed to OpenShift as well. From here you can click on the open URL circle, and a new browser tab should open to lead you to your PetClinic's front page. Interacting with Your PetClinic Application and MySQL database \u00b6 In this section, you will add a new owner to the Pet Clinic application, and then go into your MySQL container to see if that owner was successfully added. 1. You Pet Clinic should look something similar to this. Go to the Find Owners tab, and create a new owner. 2. Click on the Add Owner button, and add an owner of your own, for example: 3. You can then go back to Find Owners and try searching for the owner that you just added. It should come back with the search results similar to the following. 4. Now let's check the MySQL database to make sure that the new owner you just added is in there. Return to your OpenShift console, from the Topology view, click on the mysql icon. This will bring up a side panel, and then click on the mysql pod (your pod name will be different than the picture): In the pod panel, go to the Terminal tab. Now type in the following commands in your mysql terminal: Let's run a SQL command now to verify that the owner that we added through the application is indeed in the database: Please let the instructors know, if you don't see your owner listed. Congratulations, you have completed this part of the workshop! You may move on to the next part, PetClinic + OpenShift Pipelines = CI .","title":"PetClinic Up and Running"},{"location":"build-and-deploy/upandrunning/#getting-your-petclinic-up-and-running","text":"For this workshop we will be using the iconic Spring PetClinic application. The Spring PetClinic is a sample application designed to show how the Spring stack can be used to build simple, but powerful database-oriented applications. The official version of PetClinic demonstrates the use of Spring Boot with Spring MVC and Spring Data JPA. We will not be focusing on the ins and outs of the PetClinic application itself, but rather on leveraging OpenShift tooling to build a PetClinic cloud-native application and a DevOps pipeline for the application. We will start by building our PetClinic application from the source code and connecting it to a MySQL database. Using LinuxONE Community Cloud Because you are using the LinuxONE Community Cloud OpenShift trial, your project name will be different from the project name depicted in the diagrams below. You will be operating in your assigned project for the entirety of the lab. Lab Guide For the images in this lab: - the green arrows or boxes denote something to look at or reference - the red arrows or boxes denote something to click on or type.","title":"Getting Your PetClinic Up and Running"},{"location":"build-and-deploy/upandrunning/#deploying-mysql-database","text":"1. First, we need to setup our mysql database. Luckily, this is very easy on OpenShift with the mysql template available from the main developer topology window. Follow the steps in the diagram below to bring up the available database options. (Note your project name will be different than the picture below) 2. Next, select the MySQL (Ephemeral) tile. Note we are choosing the ephemeral option because at this point we do not care to persist the database beyond the life of the container. 3. Click on instantiate template. 4. Fill the wizard with the parameters as shown in the image below (your namespace will be different from the image below): Click the Create button. Why Ephemeral? We are using the Ephemeral implementation because this a short-lived demo and we do not need to retain the data. In a staging or production environment, you will most likely be using a MySQL deployment backed by a Persistent Volume Claim. This stores the data in a Persistent Volume (basically a virtual hard drive), and the data will persist beyond the life of the container. A minute or two later, in the Topology view of your OpenShift Console, you should see mysql in running state. (Click on the Topology icon for mysql to bring up the side panel)","title":"Deploying MySQL database"},{"location":"build-and-deploy/upandrunning/#fork-the-petclinic-repo-to-your-own-github-account","text":"For this workshop, you will be using the PetClinic application from your own GitHub account so that you can enable integrations with it later. To make a copy of the PetClinic application into your GitHub account, navigate to the following from your browser: https://github.com/ibm-wsc/spring-petclinic Then click on the fork button on the upper right corner. At this point you might need to log into GitHub if you weren't logged in already. Next, you might be presented with a screen to ask you to select where to fork to. Select your own user account to fork to. Please make a note of your repo URL for later. It should be something like: https://github.com/<your-github-username>/spring-petclinic That's it! You are ready to move on to the next section.","title":"Fork the PetClinic repo to your own GitHub account"},{"location":"build-and-deploy/upandrunning/#building-and-deploying-petclinic-application","text":"There are multiple ways OpenShift enables cloud-native application developers to package up their applications and deploy them. For PetClinic, we will be building our application image from source, leveraging OpenShift's S2I (Source to Image) capability. This allows us to quickly test the building, packaging, and deployment of our application, and gives us the option to create and use a DevOps pipeline from this workflow. It's a good way to start to understand how OpenShift Pipelines work. 1. Start with choosing Add From Git: 2. Enter https://github.com/<your-github-ID>/spring-petclinic in the Git Repo URL field. Expand the Show Advanced Git Options section, and type in main for the Git Reference . This tells OpenShift which GitHub repo and branch to pull the source code from. 3. Scroll down to the Builder section. Select the OpenJ9 tile and select openj9-11-el8 as the builder image version. As you can see OpenShift offers many different builder images to help you build images from a variety of programming languages. Your list of builder images might differ from the screen shot. For Java on Z, the recommended JVM is OpenJ9 because it has built-in s390x optimizations as well as container optimizations. 4. In the General section, put in the following entries for Application Name and Name. 5. Scroll down to the Pipelines section, and check off the box next to Add pipeline . You can also expand the Show pipeline visualization section to see a visual of the build pipeline. 6. We are almost there! We will need to configure a couple of Advanced Options. First, click on Routing in the Advanced Options section to expand the Routing options. 7. In the Routing options section, only fill out the Security options as follows. You can leave the rest alone. These options will enable only TLS access to your PetClinic application. 8. You are done with configurations of this panel. Scroll all the way down and hit the Create button which will kick off the pipeline build of your PetClinic application. In a few seconds you will see your Topology with the new application icon. Hit the little pipeline icon in the diagram below to view the build logs. Log Streaming Gotcha in the LinuxONE CC PLEASE BEWARE that if you are using the LinuxONE Community Cloud OpenShift Trial you might see lagginess with the log streaming. If it stops streaming you might want to go back out to the Topology view and once the pipeline completes, come back to the log view to see the logs. 9. The pipeline will go through three tasks: 1. fetch-repository - this Pipeline task will clone your Git PetClinic repo for the build task. 2. build - this Pipeline task is the build process which itself is broken down into a few sub-steps. This is the longest task in the pipeline, and can take up to 15 minutes. The steps that it goes through are as follows: build steps STEP-GEN-ENV-FILE: this step generates the environment file to be used during the build process STEP-GENERATE: this step generates the Dockerfile that will be used to create the OCI image later on during the build step STEP-BUILD: this is the multi-step build process of creating an OCI image out of your Java application PetClinic. It will download the required Maven Java packages, compile the Java application, run through a set of 39 unit tests on the application, and finally build the application jar file and the OCI image. If the tests fail, this step will not complete. STEP-PUSH: this final step pushes the built OCI image to the OpenShift image registry. 3. deploy - this Pipeline task will deploy the newly built image as a running deployment in your project. After this, your application will be running in a pod and be accessible via a route. Below is an image of the log of a successful build task: 10. Now if you go back to the Topology view, you should see the application has been successfully deployed to OpenShift as well. From here you can click on the open URL circle, and a new browser tab should open to lead you to your PetClinic's front page.","title":"Building and Deploying PetClinic Application"},{"location":"build-and-deploy/upandrunning/#interacting-with-your-petclinic-application-and-mysql-database","text":"In this section, you will add a new owner to the Pet Clinic application, and then go into your MySQL container to see if that owner was successfully added. 1. You Pet Clinic should look something similar to this. Go to the Find Owners tab, and create a new owner. 2. Click on the Add Owner button, and add an owner of your own, for example: 3. You can then go back to Find Owners and try searching for the owner that you just added. It should come back with the search results similar to the following. 4. Now let's check the MySQL database to make sure that the new owner you just added is in there. Return to your OpenShift console, from the Topology view, click on the mysql icon. This will bring up a side panel, and then click on the mysql pod (your pod name will be different than the picture): In the pod panel, go to the Terminal tab. Now type in the following commands in your mysql terminal: Let's run a SQL command now to verify that the owner that we added through the application is indeed in the database: Please let the instructors know, if you don't see your owner listed. Congratulations, you have completed this part of the workshop! You may move on to the next part, PetClinic + OpenShift Pipelines = CI .","title":"Interacting with Your PetClinic Application and MySQL database"}]}