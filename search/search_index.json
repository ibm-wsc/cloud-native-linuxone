{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Cloud Native LinuxONE Workshop \u00b6 Welcome to our Cloud Native LinuxONE workshop. Developers can leverage OpenShift to create continuous integration pipelines for Linux\u00ae workloads on IBM Z\u00ae and LinuxONE. You can quickly get up and running on OpenShift with a continuous workflow. Agenda \u00b6 Introduction to Cloud Native Workshop Deploy PetClinic via OpenShift Pipelines Configure PetClinic's Integration and Deployment via OpenShift Pipelines to Meet Your Organization's Needs 1 Extend Pipeline to Upgrade from Development to Staging Acknowledgements \u00b6 Thanks to the following contributors: Chee Yee for setting up the LinuxONE Community Cloud for the OpenShift Pipelines workflow The spring developers for creating the petclinic demo and the redhat-developer-demos for sharing the spring-petclinic version of sample application we started with Key Contributors \u00b6 Barry Silliman Workshop authors \u00b6 Garrett Woodworth Jin VanStee For the purposes of this lab, you are fulfilling the requirements of a fictional organization. These requirements could change for your specific organization but would follow a similar pattern with different specifics. \u21a9","title":"Home"},{"location":"#cloud-native-linuxone-workshop","text":"Welcome to our Cloud Native LinuxONE workshop. Developers can leverage OpenShift to create continuous integration pipelines for Linux\u00ae workloads on IBM Z\u00ae and LinuxONE. You can quickly get up and running on OpenShift with a continuous workflow.","title":"Cloud Native LinuxONE Workshop"},{"location":"#agenda","text":"Introduction to Cloud Native Workshop Deploy PetClinic via OpenShift Pipelines Configure PetClinic's Integration and Deployment via OpenShift Pipelines to Meet Your Organization's Needs 1 Extend Pipeline to Upgrade from Development to Staging","title":"Agenda"},{"location":"#acknowledgements","text":"Thanks to the following contributors: Chee Yee for setting up the LinuxONE Community Cloud for the OpenShift Pipelines workflow The spring developers for creating the petclinic demo and the redhat-developer-demos for sharing the spring-petclinic version of sample application we started with","title":"Acknowledgements"},{"location":"#key-contributors","text":"Barry Silliman","title":"Key Contributors"},{"location":"#workshop-authors","text":"Garrett Woodworth Jin VanStee For the purposes of this lab, you are fulfilling the requirements of a fictional organization. These requirements could change for your specific organization but would follow a similar pattern with different specifics. \u21a9","title":"Workshop authors"},{"location":"glossary/","text":"OCP / OpenShift Container Platform: a platform as a service using containers maintained and distributed by Red Hat from the open source offering Origin using Kubernetes as the underlying container orchestration software. Kubernetes (k8s): an open source, extensible container orchestrator Container image: a linux application image built as a static starting point for use with a container","title":"Glossary of terms"},{"location":"introduction/","text":"Cloud Native Workshop Introduction \u00b6 You will build and deploy an application (the cloud native way) using OpenShift Container Platform and its CI/CD workflow OpenShift Pipelines. Overall Architecture Image \u00b6 One day an architecture image will sit here. Until then, enjoy this text. Lab Overview \u00b6 You will set up a virtual pet clinic (based on the classic spring boot demo referenced in the main documentation running on LinuxONE using source code on GitHub and OpenShift Pipelines to seamlessly update, test, and deploy your pet clinic. This lab is broken into three parts: Building and deploying the PetClinic Java application with OpenShift Pipelines Configuring PetClinic's integration and deployment pipeline to meet your organization's needs 1 Promoting PetClinic from development to staging with testing and GitHub integration (adding the C [continuous] in CI/CD) For the purposes of this lab you are fulfilling the requirements of a fictional organization. These requirements could change for your specific organization but would follow a similar pattern with different specifics. \u21a9","title":"Introduction"},{"location":"introduction/#cloud-native-workshop-introduction","text":"You will build and deploy an application (the cloud native way) using OpenShift Container Platform and its CI/CD workflow OpenShift Pipelines.","title":"Cloud Native Workshop Introduction"},{"location":"introduction/#overall-architecture-image","text":"One day an architecture image will sit here. Until then, enjoy this text.","title":"Overall Architecture Image"},{"location":"introduction/#lab-overview","text":"You will set up a virtual pet clinic (based on the classic spring boot demo referenced in the main documentation running on LinuxONE using source code on GitHub and OpenShift Pipelines to seamlessly update, test, and deploy your pet clinic. This lab is broken into three parts: Building and deploying the PetClinic Java application with OpenShift Pipelines Configuring PetClinic's integration and deployment pipeline to meet your organization's needs 1 Promoting PetClinic from development to staging with testing and GitHub integration (adding the C [continuous] in CI/CD) For the purposes of this lab you are fulfilling the requirements of a fictional organization. These requirements could change for your specific organization but would follow a similar pattern with different specifics. \u21a9","title":"Lab Overview"},{"location":"prerequisites/","text":"Prerequisites \u00b6 Create a GitHub \u00b6 Create a GitHub account (if you don't already have one) here . Create a LinuxONE Community Cloud OpenShift Container Platform Trial \u00b6 Create a LinuxONE Community Cloud OpenShift Container Platform trial here .","title":"Prerequisites"},{"location":"prerequisites/#prerequisites","text":"","title":"Prerequisites"},{"location":"prerequisites/#create-a-github","text":"Create a GitHub account (if you don't already have one) here .","title":"Create a GitHub"},{"location":"prerequisites/#create-a-linuxone-community-cloud-openshift-container-platform-trial","text":"Create a LinuxONE Community Cloud OpenShift Container Platform trial here .","title":"Create a LinuxONE Community Cloud OpenShift Container Platform Trial"},{"location":"proposechange/","text":"How to propose a change \u00b6 On the page you want to make a change to, click on the pencil icon next to the page's title. This will take you to edit the page in Github. You will see a message similar to the following: \"You\u2019re editing a file in a project you don\u2019t have write access to. Submitting a change to this file will write it to a new branch in your fork, so you can send a pull request.\" Make your changes in Markdown. And submit for review. The owners of this repo will review your pull request and accept or deny your change proposal. There are other ways of doing a pull request, a Google search will lead you to those tutorials.","title":"Propose a change"},{"location":"proposechange/#how-to-propose-a-change","text":"On the page you want to make a change to, click on the pencil icon next to the page's title. This will take you to edit the page in Github. You will see a message similar to the following: \"You\u2019re editing a file in a project you don\u2019t have write access to. Submitting a change to this file will write it to a new branch in your fork, so you can send a pull request.\" Make your changes in Markdown. And submit for review. The owners of this repo will review your pull request and accept or deny your change proposal. There are other ways of doing a pull request, a Google search will lead you to those tutorials.","title":"How to propose a change"},{"location":"resources/","text":"Other Resources \u00b6 OpenShift Pipelines Resources \u00b6 Information Page Intro Series on OpenShift blog","title":"Other resources"},{"location":"resources/#other-resources","text":"","title":"Other Resources"},{"location":"resources/#openshift-pipelines-resources","text":"Information Page Intro Series on OpenShift blog","title":"OpenShift Pipelines Resources"},{"location":"application-promotion/action/","text":"CI/CD in Action \u00b6 Make a change in GitHub \u00b6 Navigate to your GitHub fork's main page (this is the Code tab if you are on a different tab such as settings) Choose to Go to file Choose the following file (copy and paste box below image): src/main/resources/db/mysql/data.sql Select to edit the file Change the file to add the pet field of your choice and commit it to your GitHub fork (description and copy and paste box are below image) Make a change using the pet type you want to add (example is a turtle) Note The copy and paste box below can be entered on line 24 with enter pressed after it to match the image above. Turtle INSERT IGNORE INTO types VALUES ( 7 , 'turtle' ); I want to add Willow, an awesome armadillo, not Yertle the turtle! If you want to add something other than a turtle as an option, please change turtle to that animal (i.e. armadillo ) in the mysql statement above. For the armadillo example, the statement becomes: INSERT IGNORE INTO types VALUES ( 7 , 'armadillo' ); Type in a commit message (you can make this whatever you want) and commit the change (example from image below) Yertle the turtle Title Turtle Time Extended Description I want to be able to add Yertle the turtle. Take note of the git commit message and hash Continuous Integration via OpenShift Pipelines \u00b6 Successfully Run Pipeline via GitHub \u00b6 Visit the newly triggered pipeline run in the Pipelines menu in the OpenShift UI View the pipeline run from the Details view You can see the event listener has triggered the PipelineRun instead of a user this time. You can see the variables populated with the correct values from Github in the YAML view of the pipeline run. Watch the results of your build pipeline run. It should complete successfully as in the pictures below. What to do if your pipeline run ends in failure If your pipeline run ends in failure, please look at the Failure tab (immediately below this message) to get back on track (instead of the default Success tab). Success Pipeline Run Success View Perspective: Pipeline Run Details View In the pipeline run Details view, you can see the pipeline run succeeded with all tasks having a green check mark. Additionally, observe that the event listener has triggered the PipelineRun instead of a user this time. Pipeline Run Success Logs Perspective: Pipeline Run Logs View 1 In the pipeline run Logs view, you can also see that the pipeline run tasks all have green check marks. Looking at the last task, you can see that the that the external connection check worked and the PetClinic application is available at the route printed in the logs. Additionally, you can see via the series of tasks marked with green checks that the dev deployment ran successfully and the system cleaned it up and ran the staging deployment successfully to complete the pipeline. Pipeline Run Logs View 2 When you switch to the deploy-staging task logs, by clicking on the task on the left hand side of the Logs view of the pipeline run, you see this was an automated build from git since the task prints out the GIT_MESSAGE that you typed in your commit word for word. ( Note: If you chose a different commit message that will show instead of the one displayed in the image above. ). Failure Your pipeline failed, here is how to get back on the happy path Please review your pipelineRun and see what error caused the failure. Make changes to fix the error. (If it's unclear what is causing the error / how to fix it, please ask the instructors for help) Resend the webhook from GitHub to trigger a new pipelineRun with the same values as before (see images below for help) Click on your webhook from the Webhooks section of the repository settings for your GitHub repository fork of the spring-petclinic repository Click on the 3 dots for the most recent delivery Click Redeliver See Changes in Application \u00b6 Navigate to the Topology view and open a new tab with your recently deployed staging version of the PetClinic application by clicking Open URL . Navigate to the Find Owners tab Choose to add a new owner Add the owner with details of your choice Choose to add one of the owner's pets Fill in the pet's details and select the new type of pet you added (turtle for the example) View the newly created pet of the new type (Yertle the turtle for the example) Summary \u00b6 In this section, you made a change to your PetClinic application to add a new pet type of your choice and pushed the change to GitHub. This triggered a new pipeline run which built a new image for the application tagged with the git commit hash and displayed the commit message explaining the change the build was implementing. Next, your pipeline deployed this change to OpenShift in development, tested it internally and externally and then rolled it out to staging (where it was also tested automatically). Finally, you visited the application and used the new feature (new type of pet) by adding a pet of that type to a new owner successfully. In other words, you are off the ground and running with \"cloud native\" CI/CD for your PetClinic application on IBM Z/LinuxONE! Congratulations!!!","title":"CI/CD in Action"},{"location":"application-promotion/action/#cicd-in-action","text":"","title":"CI/CD in Action"},{"location":"application-promotion/action/#make-a-change-in-github","text":"Navigate to your GitHub fork's main page (this is the Code tab if you are on a different tab such as settings) Choose to Go to file Choose the following file (copy and paste box below image): src/main/resources/db/mysql/data.sql Select to edit the file Change the file to add the pet field of your choice and commit it to your GitHub fork (description and copy and paste box are below image) Make a change using the pet type you want to add (example is a turtle) Note The copy and paste box below can be entered on line 24 with enter pressed after it to match the image above. Turtle INSERT IGNORE INTO types VALUES ( 7 , 'turtle' ); I want to add Willow, an awesome armadillo, not Yertle the turtle! If you want to add something other than a turtle as an option, please change turtle to that animal (i.e. armadillo ) in the mysql statement above. For the armadillo example, the statement becomes: INSERT IGNORE INTO types VALUES ( 7 , 'armadillo' ); Type in a commit message (you can make this whatever you want) and commit the change (example from image below) Yertle the turtle Title Turtle Time Extended Description I want to be able to add Yertle the turtle. Take note of the git commit message and hash","title":"Make a change in GitHub"},{"location":"application-promotion/action/#continuous-integration-via-openshift-pipelines","text":"","title":"Continuous Integration via OpenShift Pipelines"},{"location":"application-promotion/action/#successfully-run-pipeline-via-github","text":"Visit the newly triggered pipeline run in the Pipelines menu in the OpenShift UI View the pipeline run from the Details view You can see the event listener has triggered the PipelineRun instead of a user this time. You can see the variables populated with the correct values from Github in the YAML view of the pipeline run. Watch the results of your build pipeline run. It should complete successfully as in the pictures below. What to do if your pipeline run ends in failure If your pipeline run ends in failure, please look at the Failure tab (immediately below this message) to get back on track (instead of the default Success tab). Success Pipeline Run Success View Perspective: Pipeline Run Details View In the pipeline run Details view, you can see the pipeline run succeeded with all tasks having a green check mark. Additionally, observe that the event listener has triggered the PipelineRun instead of a user this time. Pipeline Run Success Logs Perspective: Pipeline Run Logs View 1 In the pipeline run Logs view, you can also see that the pipeline run tasks all have green check marks. Looking at the last task, you can see that the that the external connection check worked and the PetClinic application is available at the route printed in the logs. Additionally, you can see via the series of tasks marked with green checks that the dev deployment ran successfully and the system cleaned it up and ran the staging deployment successfully to complete the pipeline. Pipeline Run Logs View 2 When you switch to the deploy-staging task logs, by clicking on the task on the left hand side of the Logs view of the pipeline run, you see this was an automated build from git since the task prints out the GIT_MESSAGE that you typed in your commit word for word. ( Note: If you chose a different commit message that will show instead of the one displayed in the image above. ). Failure Your pipeline failed, here is how to get back on the happy path Please review your pipelineRun and see what error caused the failure. Make changes to fix the error. (If it's unclear what is causing the error / how to fix it, please ask the instructors for help) Resend the webhook from GitHub to trigger a new pipelineRun with the same values as before (see images below for help) Click on your webhook from the Webhooks section of the repository settings for your GitHub repository fork of the spring-petclinic repository Click on the 3 dots for the most recent delivery Click Redeliver","title":"Successfully Run Pipeline via GitHub"},{"location":"application-promotion/action/#see-changes-in-application","text":"Navigate to the Topology view and open a new tab with your recently deployed staging version of the PetClinic application by clicking Open URL . Navigate to the Find Owners tab Choose to add a new owner Add the owner with details of your choice Choose to add one of the owner's pets Fill in the pet's details and select the new type of pet you added (turtle for the example) View the newly created pet of the new type (Yertle the turtle for the example)","title":"See Changes in Application"},{"location":"application-promotion/action/#summary","text":"In this section, you made a change to your PetClinic application to add a new pet type of your choice and pushed the change to GitHub. This triggered a new pipeline run which built a new image for the application tagged with the git commit hash and displayed the commit message explaining the change the build was implementing. Next, your pipeline deployed this change to OpenShift in development, tested it internally and externally and then rolled it out to staging (where it was also tested automatically). Finally, you visited the application and used the new feature (new type of pet) by adding a pet of that type to a new owner successfully. In other words, you are off the ground and running with \"cloud native\" CI/CD for your PetClinic application on IBM Z/LinuxONE! Congratulations!!!","title":"Summary"},{"location":"application-promotion/git/","text":"Integrating OpenShift Pipelines with GitHub \u00b6 It's time to add the C (continuous) to your CI/CD pipeline. Add a GitHub Trigger \u00b6 Choose Add Trigger from the pipeline menu Configure the trigger as follows (copy and paste boxes below image) and click Add to add the trigger to your pipeline: Git Provider Type : github-push Note github-push is in a menu you need to select from GIT_MESSAGE $( tt.params.git-commit-message ) COMMIT_SHA $( tt.params.git-revision ) You are choosing the github-push cluster trigger binding, which is defined out of the box for OpenShift Pipelines. This passes information into a number of different variables which you can list by clicking the expand arrow seen in the picture (It will initially say Show Variables and then switch to Hide Variables when expanded as shown in the picture). You will be using the variables in green boxes in the picture to pass the git commit message ( git-commit-message ) as well as the SHA of the git commit ( git-revision ) to the build pipeline from the GitHub webhook that triggers the build. Setting up Git Webhook \u00b6 Now, you need to set up a webhook from GitHub. You want this to hit your event listener , the pipelines resource which listens for events from outside sources in order to trigger a build. The listener you set up is using the github-push trigger binding to trigger a new pipeline run for your spring-petclinic pipeline passing the github-push parameters mentioned before. You created this event-listener via the OpenShift Pipelines UI when you added a trigger and will see it in the Topology section of the OpenShift UI as another application when you travel back there later. In order to setup your webhook to send a message to the event listener after a Github Push, do the following: Get the event listener url from the pipeline view Find the value listed for your pipeline and copy that value. Navigate to your git fork of the github.com/ibm-wsc/spring-petclinic GitHub repository Tip Your git fork should be in the form github.com/ yourusername /spring-petclinic where yourusername is your GitHub username Go to the settings page of the repository Go to the Webhooks section and add a webhook with: event listener URL as the PAYLOAD_URL application/json selected as the Content type Just the push event selected for Which events would you like to trigger this webhook? . See the successfully created webhook now listed Summary \u00b6 You created a GitHub webhook for your spring-petclinic repository fork that will trigger a new run of your spring-petclinic pipeline when new code is pushed to your GitHub repo 1 . You will trigger your pipeline via GitHub in the next section. A more detailed explanation is that when new code is pushed to your GitHub repo, the GitHub webhook will send a payload to the event listener which then interacts with a number of OpenShift Pipelines-associated Kubernetes custom resources that you created when you used the Add Trigger button in the UI. Namely, the event listener will trigger a new PipelineRun of your spring-petclinic pipeline based on the spring-petclinic TriggerTemplate passing it the values for the git commit SHA hash and the commit message using the variables populated via the github-push ClusterTriggerBinding . \u21a9","title":"Integrating Git"},{"location":"application-promotion/git/#integrating-openshift-pipelines-with-github","text":"It's time to add the C (continuous) to your CI/CD pipeline.","title":"Integrating OpenShift Pipelines with GitHub"},{"location":"application-promotion/git/#add-a-github-trigger","text":"Choose Add Trigger from the pipeline menu Configure the trigger as follows (copy and paste boxes below image) and click Add to add the trigger to your pipeline: Git Provider Type : github-push Note github-push is in a menu you need to select from GIT_MESSAGE $( tt.params.git-commit-message ) COMMIT_SHA $( tt.params.git-revision ) You are choosing the github-push cluster trigger binding, which is defined out of the box for OpenShift Pipelines. This passes information into a number of different variables which you can list by clicking the expand arrow seen in the picture (It will initially say Show Variables and then switch to Hide Variables when expanded as shown in the picture). You will be using the variables in green boxes in the picture to pass the git commit message ( git-commit-message ) as well as the SHA of the git commit ( git-revision ) to the build pipeline from the GitHub webhook that triggers the build.","title":"Add a GitHub Trigger"},{"location":"application-promotion/git/#setting-up-git-webhook","text":"Now, you need to set up a webhook from GitHub. You want this to hit your event listener , the pipelines resource which listens for events from outside sources in order to trigger a build. The listener you set up is using the github-push trigger binding to trigger a new pipeline run for your spring-petclinic pipeline passing the github-push parameters mentioned before. You created this event-listener via the OpenShift Pipelines UI when you added a trigger and will see it in the Topology section of the OpenShift UI as another application when you travel back there later. In order to setup your webhook to send a message to the event listener after a Github Push, do the following: Get the event listener url from the pipeline view Find the value listed for your pipeline and copy that value. Navigate to your git fork of the github.com/ibm-wsc/spring-petclinic GitHub repository Tip Your git fork should be in the form github.com/ yourusername /spring-petclinic where yourusername is your GitHub username Go to the settings page of the repository Go to the Webhooks section and add a webhook with: event listener URL as the PAYLOAD_URL application/json selected as the Content type Just the push event selected for Which events would you like to trigger this webhook? . See the successfully created webhook now listed","title":"Setting up Git Webhook"},{"location":"application-promotion/git/#summary","text":"You created a GitHub webhook for your spring-petclinic repository fork that will trigger a new run of your spring-petclinic pipeline when new code is pushed to your GitHub repo 1 . You will trigger your pipeline via GitHub in the next section. A more detailed explanation is that when new code is pushed to your GitHub repo, the GitHub webhook will send a payload to the event listener which then interacts with a number of OpenShift Pipelines-associated Kubernetes custom resources that you created when you used the Add Trigger button in the UI. Namely, the event listener will trigger a new PipelineRun of your spring-petclinic pipeline based on the spring-petclinic TriggerTemplate passing it the values for the git commit SHA hash and the commit message using the variables populated via the github-push ClusterTriggerBinding . \u21a9","title":"Summary"},{"location":"application-promotion/promote/","text":"Automatically Testing and Promoting your Application \u00b6 Here you will edit your pipeline to test your application in development, clean up your development resources, promote your application to staging, and test it in staging. Testing your Application in the Wild \u00b6 During the build stage of your pipeline, you tested two things: That the pieces of your application worked (unit testing) That they worked together (integration testing) Now, it's time to go a step further and automate testing that your application is working and accessible when deployed in a real (OpenShift) environment: Internally (within OpenShift) Externally (the outside world) Internally (Within Kubernetes/OpenShift) \u00b6 The first thing you need to test is that the application is alive and available from within your cluster (Kubernetes environment). This is important not only for when running the CI/CD pipeline, but also for any time your application is running (downtime is detrimental, especially in production). This functionality is available in Kubernetes via probes . There are 3 different types of probes to test the different aspects of your application's availability: Kubernetes Probes in Spring In Spring there are built-in endpoints for Kubernetes probes. If you are interested in learning how to program these into a Spring application of yours in the future, please take a look at Spring's official blog . Startup probes: Activate first Make sure an application is up and running (started up) Free startup concerns/constraints from other probes Here is the startupProbe for the container running the PetClinic application: startupProbe : httpGet : path : /actuator/health/liveness port : 8080 periodSeconds : 10 failureThreshold : 30 It simply queries (via localhost) PetClinic's liveness health endpoint. Once this returns successfully, you can be confident the application has started up and can begin to monitor the liveness and readiness of each container of each replica (pod) of your application throughout its lifecycle. Liveness probes: Make sure an application is actually running and not caught in a deadlock (it's alive) Restart \"dead\" containers automatically with kubelet Fix problems that may arise in long-running containers via the aforementioned restart Here is the livenessProbe for the container running the PetClinic application: livenessProbe : httpGet : path : /actuator/health/liveness port : 8080 periodSeconds : 10 failureThreshold : 3 This looks almost identical to the startupProbe above other than having a much lower failureThreshold . The startupProbe is making sure the container of a given pod of your application's deployment is alive when it first starts up (It is allowing time for that startup to occur). On the other hand, the liveness probe above is making sure your application stays alive throughout its lifecycle. Therefore, it has a much lower failureThreshold to enable kubelet to quickly respond (restart the container) when the container becomes deadlocked. Readiness probes: Check if each copy (replica) of an application is ready Makes sure traffic goes only to replicas that are ready for it Prevents users from interacting with unready replicas (getting unnecessary errors) Here is the readinessProbe for the container running PetClinic: readinessProbe : httpGet : path : /actuator/health/readiness port : 8080 periodSeconds : 10 It simply queries (via localhost) PetClinic's readiness health endpoint. This probe will let Kubernetes know when to send traffic to a PetClinic replica. When you send traffic to the application, only the available replicas will receive it. This means that replicas which aren't ready for traffic don't accidentally get it, preventing errors for the user. These 3 probes serve to declare to Kubernetes the way your application (and the replicas that make it up) should behave, enabling the system to monitor and take action on your behalf (restarting the container or removing its pod's endpoint from service) when the current state (the status) does not meet the desired state (your specification). The rollout task you created before as deploy-dev will only complete once all desired replicas are ready, implying that both the startup (initial liveness) and readiness probes have successfully passed and all replicas of your application are initially alive and ready for business. Testing External Connections \u00b6 While making sure your application is internally up and running is important, at the end of the day you want to provide access to your users externally 1 . This means it is important to also test the OpenShift route (the component providing the external connection) as part of your CI/CD pipeline to ensure it is correctly servicing web traffic external to your cluster 2 . Create External Route Test Task \u00b6 You will create a task to check the connection to your external route as part of your CI/CD pipeline. Copy the connection-test task using the following definition (copy by clicking on the copy icon in the top right of the box below): apiVersion : tekton.dev/v1beta1 kind : Task metadata : name : connection-test spec : description : >- \"This task runs a bash script to determine if a given application is accessible to the outside world via its route.\" params : - name : ROUTE_NAME default : \"\" description : \"The name of the OpenShift route for the application.\" type : string - name : APP_PATH default : \"/\" description : \"The path to reach the application from it's hostname\" type : string - name : EXPECTED_STATUS default : \"200\" description : \"The expected http(s) status code from querying the application.\" type : string - name : TIMEOUT default : \"30\" description : \"The number of seconds to try before giving up on a successful connection.\" type : string - name : SECURE_CONNECTION default : \"true\" description : \"true for a secure route (https), false for an insecure (http) route.\" type : string steps : - name : route-connection-test image : 'image-registry.openshift-image-registry.svc:5000/openshift/cli:latest' resources : limits : cpu : 200m memory : 200Mi requests : cpu : 200m memory : 200Mi script : | #!/usr/bin/env bash # Make parameters into variables for clarity export route_name=\"$(params.ROUTE_NAME)\" export expected_status=\"$(params.EXPECTED_STATUS)\" export app_path=\"$(params.APP_PATH)\" export timeout=\"$(params.TIMEOUT)\" export secure_connection=\"$(params.SECURE_CONNECTION)\" # If true, http(s), if false (or otherwise) http if [ \"${secure_connection}\" == \"true\" ] then export header=\"https://\" echo \"Using secure https connection...\" else export header=\"http://\" echo \"Using insecure http connection...\" fi # Start timer at 0 SECONDS=0 # Once timeout reached, stop retrying while [ \"${SECONDS}\" -lt \"${timeout}\" ]; do # Get hostname of route hostname=\"$(oc get route ${route_name} -o jsonpath='{.spec.host}')\" # Get http(s) status of web page via external connection (route) status=$(curl -s -o /dev/null -w \"%{http_code}\" \"${header}${hostname}${app_path}\") # Print test completion message if expected status code received if [ \"${status}\" -eq \"${expected_status}\" ] then echo \"---------------------------TESTS COMPLETE---------------------------\" echo \"Congratulations on a successful test!\" echo \"Please visit the application at:\" echo echo \"${header}${hostname}${app_path}\" exit 0 # Print failure message if incorrect status code received + retry else echo \"The application is unexpectedly returning http(s) code ${status}...\" echo \"It is not available to outside traffic yet...\" echo \"Retrying in 5s at:\" echo echo \"${header}${hostname}${app_path}\" sleep 5 fi done # Redirect output to standard error, print message, and exit with error after timeout >&2 echo \"Error, failed after ${timeout} seconds of trying...\" >&2 echo \"The application was never accessible to the outside world :(\" exit 1 2. Create the connection-test Task a. Click Import YAML to bring up the box where you can create Kubernetes resource definitions from yaml b. Paste the connection-test Task into the box c. Scroll down and click create to create the connection-test Task You should now see the created connection-test Task. Navigate back to the Pipelines section of the OpenShift UI and go back to editing your pipeline. Add External Route Test Task to Pipeline \u00b6 Add a sequential task after deploy-dev . When you Select Task , choose the connection-test task. Configure connection-test task The only values you need to change are the Display Name and the ROUTE_NAME (copy and paste boxes below image): Display Name connect-dev ROUTE_NAME spring-petclinic-dev Save pipeline Your current pipeline builds and tests your application, creates a docker image for it, deploys it to the development environment, and ensures that the application is working both internally and externally. In other words, once your application successfully completes the current pipeline, you can be confident in it and be ready to move to staging 3 . Deploy Staging \u00b6 Moving to the staging environment means spinning up your application in that environment (with parameters relevant for it) and testing it there. Given that this is all using containers, you can easily free up the development resources that have successfully completed and then spin up the new resources in your staging environment. Remove Dev \u00b6 Your first Task will mirror the cleanup-resources task at the beginning of your pipeline but cleanup just the dev resources using the env=dev label selector . Go back to editing your pipeline via Actions -> Edit Pipeline Add a Task sequentially at the end of the pipeline (after connect-dev ) using the openshift-client ClusterTask. Configure the Task with the following values (copy and paste boxes below image): Display Name cleanup-dev SCRIPT oc delete deployment,cm,svc,route -l app = spring-petclinic,env = dev --ignore-not-found and an empty ARGS value. No help please! Make sure help is deleted from the ARGS section (it will be greyed out once deleted) or bad things will happen (i.e. the help screen will come up instead of the proper command running). Add Staging \u00b6 You will use your existing kustomize task to deploy the staging configuration for your PetClinic application in a new kustomize-staging task. Customizations for staging PetClinic include adding a staging environment label, name suffix, change cause, and staging environment variables for your application. You could deploy to a separate project or cluster altogether as well as change replicas or add pod autoscalers in a similar manner (depending on your use case) for different environments. Add a kustomize task sequentially to the end of your current pipeline (after cleanup-dev ) Configure the Task with the following values (copy and paste boxes below image): Display Name kustomize-staging RELEASE_SUBDIR overlay/staging SCRIPT kustomize edit set image spring-petclinic = $( params.IMAGE_NAME ) -minimal: $( params.COMMIT_SHA ) Save current pipeline edit and then switch to YAML from pipeline menu. Why are you editing yaml directly? Workspaces are more versatile than traditional PipelineResources which is why you are using them. However, as the transition to workspaces continues, the OpenShift Pipeline Builder doesn't support editing the Workspace mapping from a pipeline to a task via the Builder UI so you have to do it directly in the yaml for now. Add workspace to kustomize-staging task Find the kustomize-staging and add the following workspace definition: workspaces: - name: source workspace: workspace Save the update Note After the save message above appears you can then proceed to Cancel back to the pipeline menu. Rollout Staging \u00b6 Edit the pipeline again and add a deploy-staging task with the openshift-client ClusterTask Configure the task with the following parameters 4 (copy and paste boxes below image): Display Name deploy-staging SCRIPT echo \" $( params.GIT_MESSAGE ) \" && oc rollout status deploy/spring-petclinic-staging No help please! Make sure help is deleted from the ARGS section (it will be greyed out once deleted) or bad things will happen (i.e. the help screen will come up instead of the proper command running). Add External Route Test Task to Pipeline \u00b6 Add a sequential task after deploy-staging . When you Select Task , choose the connection-test task. Configure connection-test task The only values you need to change are the Display Name and the ROUTE_NAME : Display Name connect-staging ROUTE_NAME spring-petclinic-staging Save pipeline Summary \u00b6 Congratulations! You have built a pipeline that tests your PetClinic application, creates a docker image for it, deploys it to the development environment with dev configuration, ensures that the application is working both internally and externally, cleans up the development environment, deploys it to the staging environment with staging configuration and then makes sure it is working both internally and externally 5 . tl;dr You now have the I/D (Integration/Deployment) in CI/CD 6 . For different environments like dev and test, this may be different groups external to your Kubernetes environment (cluster), though internal to the organization itself and accessing the endpoints via a VPN or internal network. Production is likely when external connection via an organization's real website would happen. The type of external connection (via a VPN or public connection) has little impact on the Kubernetes resources given a route will be used for all of those types of external connections (the most important thing is that the route you are testing is available to you [the tester] from where you are). \u21a9 You may think to yourself that you can't test an external connection from inside your cluster. However, by using the route you are causing the traffic to go \"outside\" the cluster's networking to reach the load balancer and then back \"inside\" via the route, explicitly testing the external connection and making sure that it indeed works. This just tests that the route works, not that the dns/hostname is available generally on the internet or private enterprise subnet (depending on environment). Internet / subnet dns resolution is a different more general problem for your networking team (or cloud) to ensure for all of your applications using that network. \u21a9 You could create more extensive tests to make sure that the pages are rendering correctly (besides just returning a proper status code). However, that is beyond the scope of the lab and this at least makes sure requests are successfully sent and returned via an external route, which is good enough for the lab's purposes. \u21a9 This mirrors the dev-deploy task which waits for the dev release to rollout but uses the SCRIPT field for everything vs. ARGS . \u21a9 You could clean up the staging environment at the end of the run but choose not to so that the user can interact with it between runs. You could also clean up or use a separate MySQL instance for staging but due to limited resources in your environment you have chosen not to add this extra component. \u21a9 You'll add the double C s in the next section by connecting it to GitHub. \u21a9","title":"Promoting Application"},{"location":"application-promotion/promote/#automatically-testing-and-promoting-your-application","text":"Here you will edit your pipeline to test your application in development, clean up your development resources, promote your application to staging, and test it in staging.","title":"Automatically Testing and Promoting your Application"},{"location":"application-promotion/promote/#testing-your-application-in-the-wild","text":"During the build stage of your pipeline, you tested two things: That the pieces of your application worked (unit testing) That they worked together (integration testing) Now, it's time to go a step further and automate testing that your application is working and accessible when deployed in a real (OpenShift) environment: Internally (within OpenShift) Externally (the outside world)","title":"Testing your Application in the Wild"},{"location":"application-promotion/promote/#internally-within-kubernetesopenshift","text":"The first thing you need to test is that the application is alive and available from within your cluster (Kubernetes environment). This is important not only for when running the CI/CD pipeline, but also for any time your application is running (downtime is detrimental, especially in production). This functionality is available in Kubernetes via probes . There are 3 different types of probes to test the different aspects of your application's availability: Kubernetes Probes in Spring In Spring there are built-in endpoints for Kubernetes probes. If you are interested in learning how to program these into a Spring application of yours in the future, please take a look at Spring's official blog . Startup probes: Activate first Make sure an application is up and running (started up) Free startup concerns/constraints from other probes Here is the startupProbe for the container running the PetClinic application: startupProbe : httpGet : path : /actuator/health/liveness port : 8080 periodSeconds : 10 failureThreshold : 30 It simply queries (via localhost) PetClinic's liveness health endpoint. Once this returns successfully, you can be confident the application has started up and can begin to monitor the liveness and readiness of each container of each replica (pod) of your application throughout its lifecycle. Liveness probes: Make sure an application is actually running and not caught in a deadlock (it's alive) Restart \"dead\" containers automatically with kubelet Fix problems that may arise in long-running containers via the aforementioned restart Here is the livenessProbe for the container running the PetClinic application: livenessProbe : httpGet : path : /actuator/health/liveness port : 8080 periodSeconds : 10 failureThreshold : 3 This looks almost identical to the startupProbe above other than having a much lower failureThreshold . The startupProbe is making sure the container of a given pod of your application's deployment is alive when it first starts up (It is allowing time for that startup to occur). On the other hand, the liveness probe above is making sure your application stays alive throughout its lifecycle. Therefore, it has a much lower failureThreshold to enable kubelet to quickly respond (restart the container) when the container becomes deadlocked. Readiness probes: Check if each copy (replica) of an application is ready Makes sure traffic goes only to replicas that are ready for it Prevents users from interacting with unready replicas (getting unnecessary errors) Here is the readinessProbe for the container running PetClinic: readinessProbe : httpGet : path : /actuator/health/readiness port : 8080 periodSeconds : 10 It simply queries (via localhost) PetClinic's readiness health endpoint. This probe will let Kubernetes know when to send traffic to a PetClinic replica. When you send traffic to the application, only the available replicas will receive it. This means that replicas which aren't ready for traffic don't accidentally get it, preventing errors for the user. These 3 probes serve to declare to Kubernetes the way your application (and the replicas that make it up) should behave, enabling the system to monitor and take action on your behalf (restarting the container or removing its pod's endpoint from service) when the current state (the status) does not meet the desired state (your specification). The rollout task you created before as deploy-dev will only complete once all desired replicas are ready, implying that both the startup (initial liveness) and readiness probes have successfully passed and all replicas of your application are initially alive and ready for business.","title":"Internally (Within Kubernetes/OpenShift)"},{"location":"application-promotion/promote/#testing-external-connections","text":"While making sure your application is internally up and running is important, at the end of the day you want to provide access to your users externally 1 . This means it is important to also test the OpenShift route (the component providing the external connection) as part of your CI/CD pipeline to ensure it is correctly servicing web traffic external to your cluster 2 .","title":"Testing External Connections"},{"location":"application-promotion/promote/#create-external-route-test-task","text":"You will create a task to check the connection to your external route as part of your CI/CD pipeline. Copy the connection-test task using the following definition (copy by clicking on the copy icon in the top right of the box below): apiVersion : tekton.dev/v1beta1 kind : Task metadata : name : connection-test spec : description : >- \"This task runs a bash script to determine if a given application is accessible to the outside world via its route.\" params : - name : ROUTE_NAME default : \"\" description : \"The name of the OpenShift route for the application.\" type : string - name : APP_PATH default : \"/\" description : \"The path to reach the application from it's hostname\" type : string - name : EXPECTED_STATUS default : \"200\" description : \"The expected http(s) status code from querying the application.\" type : string - name : TIMEOUT default : \"30\" description : \"The number of seconds to try before giving up on a successful connection.\" type : string - name : SECURE_CONNECTION default : \"true\" description : \"true for a secure route (https), false for an insecure (http) route.\" type : string steps : - name : route-connection-test image : 'image-registry.openshift-image-registry.svc:5000/openshift/cli:latest' resources : limits : cpu : 200m memory : 200Mi requests : cpu : 200m memory : 200Mi script : | #!/usr/bin/env bash # Make parameters into variables for clarity export route_name=\"$(params.ROUTE_NAME)\" export expected_status=\"$(params.EXPECTED_STATUS)\" export app_path=\"$(params.APP_PATH)\" export timeout=\"$(params.TIMEOUT)\" export secure_connection=\"$(params.SECURE_CONNECTION)\" # If true, http(s), if false (or otherwise) http if [ \"${secure_connection}\" == \"true\" ] then export header=\"https://\" echo \"Using secure https connection...\" else export header=\"http://\" echo \"Using insecure http connection...\" fi # Start timer at 0 SECONDS=0 # Once timeout reached, stop retrying while [ \"${SECONDS}\" -lt \"${timeout}\" ]; do # Get hostname of route hostname=\"$(oc get route ${route_name} -o jsonpath='{.spec.host}')\" # Get http(s) status of web page via external connection (route) status=$(curl -s -o /dev/null -w \"%{http_code}\" \"${header}${hostname}${app_path}\") # Print test completion message if expected status code received if [ \"${status}\" -eq \"${expected_status}\" ] then echo \"---------------------------TESTS COMPLETE---------------------------\" echo \"Congratulations on a successful test!\" echo \"Please visit the application at:\" echo echo \"${header}${hostname}${app_path}\" exit 0 # Print failure message if incorrect status code received + retry else echo \"The application is unexpectedly returning http(s) code ${status}...\" echo \"It is not available to outside traffic yet...\" echo \"Retrying in 5s at:\" echo echo \"${header}${hostname}${app_path}\" sleep 5 fi done # Redirect output to standard error, print message, and exit with error after timeout >&2 echo \"Error, failed after ${timeout} seconds of trying...\" >&2 echo \"The application was never accessible to the outside world :(\" exit 1 2. Create the connection-test Task a. Click Import YAML to bring up the box where you can create Kubernetes resource definitions from yaml b. Paste the connection-test Task into the box c. Scroll down and click create to create the connection-test Task You should now see the created connection-test Task. Navigate back to the Pipelines section of the OpenShift UI and go back to editing your pipeline.","title":"Create External Route Test Task"},{"location":"application-promotion/promote/#add-external-route-test-task-to-pipeline","text":"Add a sequential task after deploy-dev . When you Select Task , choose the connection-test task. Configure connection-test task The only values you need to change are the Display Name and the ROUTE_NAME (copy and paste boxes below image): Display Name connect-dev ROUTE_NAME spring-petclinic-dev Save pipeline Your current pipeline builds and tests your application, creates a docker image for it, deploys it to the development environment, and ensures that the application is working both internally and externally. In other words, once your application successfully completes the current pipeline, you can be confident in it and be ready to move to staging 3 .","title":"Add External Route Test Task to Pipeline"},{"location":"application-promotion/promote/#deploy-staging","text":"Moving to the staging environment means spinning up your application in that environment (with parameters relevant for it) and testing it there. Given that this is all using containers, you can easily free up the development resources that have successfully completed and then spin up the new resources in your staging environment.","title":"Deploy Staging"},{"location":"application-promotion/promote/#remove-dev","text":"Your first Task will mirror the cleanup-resources task at the beginning of your pipeline but cleanup just the dev resources using the env=dev label selector . Go back to editing your pipeline via Actions -> Edit Pipeline Add a Task sequentially at the end of the pipeline (after connect-dev ) using the openshift-client ClusterTask. Configure the Task with the following values (copy and paste boxes below image): Display Name cleanup-dev SCRIPT oc delete deployment,cm,svc,route -l app = spring-petclinic,env = dev --ignore-not-found and an empty ARGS value. No help please! Make sure help is deleted from the ARGS section (it will be greyed out once deleted) or bad things will happen (i.e. the help screen will come up instead of the proper command running).","title":"Remove Dev"},{"location":"application-promotion/promote/#add-staging","text":"You will use your existing kustomize task to deploy the staging configuration for your PetClinic application in a new kustomize-staging task. Customizations for staging PetClinic include adding a staging environment label, name suffix, change cause, and staging environment variables for your application. You could deploy to a separate project or cluster altogether as well as change replicas or add pod autoscalers in a similar manner (depending on your use case) for different environments. Add a kustomize task sequentially to the end of your current pipeline (after cleanup-dev ) Configure the Task with the following values (copy and paste boxes below image): Display Name kustomize-staging RELEASE_SUBDIR overlay/staging SCRIPT kustomize edit set image spring-petclinic = $( params.IMAGE_NAME ) -minimal: $( params.COMMIT_SHA ) Save current pipeline edit and then switch to YAML from pipeline menu. Why are you editing yaml directly? Workspaces are more versatile than traditional PipelineResources which is why you are using them. However, as the transition to workspaces continues, the OpenShift Pipeline Builder doesn't support editing the Workspace mapping from a pipeline to a task via the Builder UI so you have to do it directly in the yaml for now. Add workspace to kustomize-staging task Find the kustomize-staging and add the following workspace definition: workspaces: - name: source workspace: workspace Save the update Note After the save message above appears you can then proceed to Cancel back to the pipeline menu.","title":"Add Staging"},{"location":"application-promotion/promote/#rollout-staging","text":"Edit the pipeline again and add a deploy-staging task with the openshift-client ClusterTask Configure the task with the following parameters 4 (copy and paste boxes below image): Display Name deploy-staging SCRIPT echo \" $( params.GIT_MESSAGE ) \" && oc rollout status deploy/spring-petclinic-staging No help please! Make sure help is deleted from the ARGS section (it will be greyed out once deleted) or bad things will happen (i.e. the help screen will come up instead of the proper command running).","title":"Rollout Staging"},{"location":"application-promotion/promote/#add-external-route-test-task-to-pipeline_1","text":"Add a sequential task after deploy-staging . When you Select Task , choose the connection-test task. Configure connection-test task The only values you need to change are the Display Name and the ROUTE_NAME : Display Name connect-staging ROUTE_NAME spring-petclinic-staging Save pipeline","title":"Add External Route Test Task to Pipeline"},{"location":"application-promotion/promote/#summary","text":"Congratulations! You have built a pipeline that tests your PetClinic application, creates a docker image for it, deploys it to the development environment with dev configuration, ensures that the application is working both internally and externally, cleans up the development environment, deploys it to the staging environment with staging configuration and then makes sure it is working both internally and externally 5 . tl;dr You now have the I/D (Integration/Deployment) in CI/CD 6 . For different environments like dev and test, this may be different groups external to your Kubernetes environment (cluster), though internal to the organization itself and accessing the endpoints via a VPN or internal network. Production is likely when external connection via an organization's real website would happen. The type of external connection (via a VPN or public connection) has little impact on the Kubernetes resources given a route will be used for all of those types of external connections (the most important thing is that the route you are testing is available to you [the tester] from where you are). \u21a9 You may think to yourself that you can't test an external connection from inside your cluster. However, by using the route you are causing the traffic to go \"outside\" the cluster's networking to reach the load balancer and then back \"inside\" via the route, explicitly testing the external connection and making sure that it indeed works. This just tests that the route works, not that the dns/hostname is available generally on the internet or private enterprise subnet (depending on environment). Internet / subnet dns resolution is a different more general problem for your networking team (or cloud) to ensure for all of your applications using that network. \u21a9 You could create more extensive tests to make sure that the pages are rendering correctly (besides just returning a proper status code). However, that is beyond the scope of the lab and this at least makes sure requests are successfully sent and returned via an external route, which is good enough for the lab's purposes. \u21a9 This mirrors the dev-deploy task which waits for the dev release to rollout but uses the SCRIPT field for everything vs. ARGS . \u21a9 You could clean up the staging environment at the end of the run but choose not to so that the user can interact with it between runs. You could also clean up or use a separate MySQL instance for staging but due to limited resources in your environment you have chosen not to add this extra component. \u21a9 You'll add the double C s in the next section by connecting it to GitHub. \u21a9","title":"Summary"},{"location":"application-promotion/promote_overview/","text":"It's Time to Get your Pet Clinic Ready for its Internal Debut \u00b6 In this section, you will bring PetClinic from development to staging for the internal showcase of your pet clinic (staging). Promotion Tasks Check successful connection of PetClinic dev version Deploy PetClinic staging version Check successful connection of PetClinic staging version Git Tasks Add GitHub trigger to pipeline Pass git commit messages and hashes to pipeline Version images by git commit Add webhook to GitHub so it will trigger a new PipelineRun for each push Running Pipeline Update PetClinic with new animal type and push to GitHub Watch GitHub trigger PipelineRun Watch app move from dev to staging seamlessly with images tagged with git commit SHA Interact with the PetClinic application in staging using the new animal type","title":"Test and Promote Overview"},{"location":"application-promotion/promote_overview/#its-time-to-get-your-pet-clinic-ready-for-its-internal-debut","text":"In this section, you will bring PetClinic from development to staging for the internal showcase of your pet clinic (staging). Promotion Tasks Check successful connection of PetClinic dev version Deploy PetClinic staging version Check successful connection of PetClinic staging version Git Tasks Add GitHub trigger to pipeline Pass git commit messages and hashes to pipeline Version images by git commit Add webhook to GitHub so it will trigger a new PipelineRun for each push Running Pipeline Update PetClinic with new animal type and push to GitHub Watch GitHub trigger PipelineRun Watch app move from dev to staging seamlessly with images tagged with git commit SHA Interact with the PetClinic application in staging using the new animal type","title":"It's Time to Get your Pet Clinic Ready for its Internal Debut"},{"location":"build-and-deploy/build_overview/","text":"It's Time to Open up your Pet Clinic for Testing \u00b6 In this section, you will build, test and deploy the Java web application for your pet clinic (PetClinic) to get it up and running on OpenShift . This involves the following tasks: Deploying MySQL database Building and deploying PetClinic with automated testing Accessing PetClinic and adding an owner","title":"Build and Deploy Overview"},{"location":"build-and-deploy/build_overview/#its-time-to-open-up-your-pet-clinic-for-testing","text":"In this section, you will build, test and deploy the Java web application for your pet clinic (PetClinic) to get it up and running on OpenShift . This involves the following tasks: Deploying MySQL database Building and deploying PetClinic with automated testing Accessing PetClinic and adding an owner","title":"It's Time to Open up your Pet Clinic for Testing"},{"location":"build-and-deploy/upandrunning/","text":"Getting Your PetClinic Application Up and Running \u00b6 For this workshop you will be using the iconic Spring PetClinic application. The Spring PetClinic is a sample application designed to show how the Spring stack can be used to build simple, but powerful database-oriented applications. The official version of PetClinic demonstrates the use of Spring Boot with Spring MVC and Spring Data JPA. You will not be focusing on the ins and outs of the PetClinic application itself, but rather on leveraging OpenShift tooling to build a PetClinic cloud native application and a DevOps pipeline for the application. You will start by building your PetClinic application from the source code and connecting it to a MySQL database. Using LinuxONE Community Cloud Because you are using the LinuxONE Community Cloud OpenShift trial, your project name will be different from the project name depicted in the diagrams below. You will be operating in your assigned project for the entirety of the lab. Lab Guide For the images in this lab: the green arrows or boxes denote something to look at or reference the red arrows or boxes denote something to click on or type. Deploying MySQL database \u00b6 1. First, you need to setup your mysql database. Luckily, this is very easy on OpenShift with the mysql template available from the main developer topology window. Follow the steps in the diagram below to bring up the available database options. (Note your project name will be different than the picture below) 2. Next, select the MySQL (Ephemeral) tile. Note You are choosing the ephemeral option because at this point you do not care to persist the database beyond the life of the container. 3. Click on instantiate template. 4. Fill the wizard with the parameters as shown in the image below (your namespace will be different from the image below): Click the Create button. Why Ephemeral? You are using the Ephemeral implementation because this a short-lived demo and you do not need to retain the data. In a staging or production environment, you will most likely be using a MySQL deployment backed by a Persistent Volume Claim. This stores the data in a Persistent Volume (basically a virtual hard drive), and the data will persist beyond the life of the container. A minute or two later, in the Topology view of your OpenShift Console, you should see mysql in the Running state. (Click on the Topology icon for mysql to bring up the side panel) Fork the PetClinic repo to your own GitHub account \u00b6 For this workshop, you will be using the PetClinic application from your own GitHub account so that you can enable integrations with it later. To make a copy of the PetClinic application into your GitHub account, navigate to the following from your browser: https://github.com/ibm-wsc/spring-petclinic Then click on the fork button on the upper right corner. At this point you might need to log into GitHub if you weren't logged in already. Next, you might be presented with a screen to ask you to select where to fork to. Select your own user account to fork to. Please make a note of your repo URL for later. It should be something like: https://github.com/<your-github-username>/spring-petclinic That's it! You are ready to move on to the next section. Building and Deploying PetClinic Application \u00b6 There are multiple ways OpenShift enables cloud native application developers to package up their applications and deploy them. For PetClinic, you will be building your application image from source, leveraging OpenShift's S2I (Source to Image) capability. This allows you to quickly test the building, packaging, and deployment of your application, and gives you the option to create and use a DevOps pipeline from this workflow. It's a good way to start to understand how OpenShift Pipelines work. 1. Start with choosing Add From Git: 2. Enter https://github.com/<your-github-ID>/spring-petclinic in the Git Repo URL field. Expand the Show Advanced Git Options section, and type in main for the Git Reference . This tells OpenShift which GitHub repo and branch to pull the source code from. 3. Scroll down to the Builder section. Select the OpenJ9 tile and select openj9-11-el8 as the builder image version. As you can see OpenShift offers many different builder images to help you build images from a variety of programming languages. Your list of builder images might differ from the screen shot. For Java on Z, the recommended JVM is OpenJ9 because it has built-in s390x optimizations as well as container optimizations. 4. In the General section, put in the following entries for Application Name and Name. 5. Scroll down to the Pipelines section, and check off the box next to Add pipeline . You can also expand the Show pipeline visualization section to see a visual of the build pipeline. 6. You are almost there! You will need to configure a couple of Advanced Options. First, click on Routing in the Advanced Options section to expand the Routing options. 7. In the Routing options section, only fill out the Security options as follows. You can leave the rest alone. These options will enable only TLS access to your PetClinic application. 8. You are done with configurations of this panel. Scroll all the way down and hit the Create button which will kick off the pipeline build of your PetClinic application. In a few seconds you will see your Topology with the new application icon. Hit the little pipeline icon in the diagram below to view the build logs. Log Streaming Gotcha in the LinuxONE CC PLEASE BEWARE that if you are using the LinuxONE Community Cloud OpenShift Trial you might see lag with the log streaming. If it stops streaming, you might want to go back out to the Topology view. You can always return to the logs view, once the pipeline completes, to see the logs. 9. The pipeline will go through three tasks: 1. fetch-repository - this Pipeline task will clone your Git PetClinic repo for the build task. 2. build - this Pipeline task is the build process which itself is broken down into a few sub-steps. This is the longest task in the pipeline, and can take up to 15 minutes. The steps that it goes through are as follows: build steps STEP-GEN-ENV-FILE: this step generates the environment file to be used during the build process STEP-GENERATE: this step generates the Dockerfile that will be used to create the OCI image later on during the build step STEP-BUILD: this is the multi-step build process of creating an OCI image out of your Java application PetClinic. It will download the required Maven Java packages, compile the Java application, run through a set of 39 unit tests on the application, and finally build the application jar file and the OCI image. If the tests fail, this step will not complete. STEP-PUSH: this final step pushes the built OCI image to the OpenShift image registry. 3. deploy - this Pipeline task will deploy the newly built image as a running deployment in your project. After this, your application will be running in a pod and be accessible via a route. Below is an image of the log of a successful build task: 10. Now if you go back to the Topology view, you should see the application has been successfully deployed to OpenShift as well. From here you can click on the open URL circle, and a new browser tab should open to lead you to your PetClinic's front page. Interacting with Your PetClinic Application and MySQL database \u00b6 In this section, you will add a new owner to the Pet Clinic application, and then go into your MySQL container to see if that owner was successfully added. 1. You Pet Clinic should look something similar to this. Go to the Find Owners tab, and create a new owner. 2. Click on the Add Owner button, and add an owner of your own, for example: 3. You can then go back to Find Owners and try searching for the owner that you just added. It should come back with the search results similar to the following. 4. Now let's check the MySQL database to make sure that the new owner you just added is in there. Return to your OpenShift console, from the Topology view, click on the mysql icon. This will bring up a side panel, and then click on the mysql pod (your pod name will be different than the picture): In the pod panel, go to the Terminal tab. Now type in the following commands in your mysql terminal (copy and paste box below image): mysql -u root -h mysql -ppetclinic use petclinic ; show tables ; Let's run a SQL command now to verify that the owner that you added through the application is indeed in the database (copy and paste box below image): select * from owners ; Tip If you added a different user than alice you should see that user in place of alice on your screen. Please let the instructors know, if you don't see your owner you added listed. Summary \u00b6 Congratulations, you have completed this part of the workshop! You have your virtual pet clinic up and running and have created an OpenShift Pipelines pipeline that you will build on in the next sections of the lab. You may move on to the next part by clicking Next on the bottom of the page.","title":"PetClinic Up and Running"},{"location":"build-and-deploy/upandrunning/#getting-your-petclinic-application-up-and-running","text":"For this workshop you will be using the iconic Spring PetClinic application. The Spring PetClinic is a sample application designed to show how the Spring stack can be used to build simple, but powerful database-oriented applications. The official version of PetClinic demonstrates the use of Spring Boot with Spring MVC and Spring Data JPA. You will not be focusing on the ins and outs of the PetClinic application itself, but rather on leveraging OpenShift tooling to build a PetClinic cloud native application and a DevOps pipeline for the application. You will start by building your PetClinic application from the source code and connecting it to a MySQL database. Using LinuxONE Community Cloud Because you are using the LinuxONE Community Cloud OpenShift trial, your project name will be different from the project name depicted in the diagrams below. You will be operating in your assigned project for the entirety of the lab. Lab Guide For the images in this lab: the green arrows or boxes denote something to look at or reference the red arrows or boxes denote something to click on or type.","title":"Getting Your PetClinic Application Up and Running"},{"location":"build-and-deploy/upandrunning/#deploying-mysql-database","text":"1. First, you need to setup your mysql database. Luckily, this is very easy on OpenShift with the mysql template available from the main developer topology window. Follow the steps in the diagram below to bring up the available database options. (Note your project name will be different than the picture below) 2. Next, select the MySQL (Ephemeral) tile. Note You are choosing the ephemeral option because at this point you do not care to persist the database beyond the life of the container. 3. Click on instantiate template. 4. Fill the wizard with the parameters as shown in the image below (your namespace will be different from the image below): Click the Create button. Why Ephemeral? You are using the Ephemeral implementation because this a short-lived demo and you do not need to retain the data. In a staging or production environment, you will most likely be using a MySQL deployment backed by a Persistent Volume Claim. This stores the data in a Persistent Volume (basically a virtual hard drive), and the data will persist beyond the life of the container. A minute or two later, in the Topology view of your OpenShift Console, you should see mysql in the Running state. (Click on the Topology icon for mysql to bring up the side panel)","title":"Deploying MySQL database"},{"location":"build-and-deploy/upandrunning/#fork-the-petclinic-repo-to-your-own-github-account","text":"For this workshop, you will be using the PetClinic application from your own GitHub account so that you can enable integrations with it later. To make a copy of the PetClinic application into your GitHub account, navigate to the following from your browser: https://github.com/ibm-wsc/spring-petclinic Then click on the fork button on the upper right corner. At this point you might need to log into GitHub if you weren't logged in already. Next, you might be presented with a screen to ask you to select where to fork to. Select your own user account to fork to. Please make a note of your repo URL for later. It should be something like: https://github.com/<your-github-username>/spring-petclinic That's it! You are ready to move on to the next section.","title":"Fork the PetClinic repo to your own GitHub account"},{"location":"build-and-deploy/upandrunning/#building-and-deploying-petclinic-application","text":"There are multiple ways OpenShift enables cloud native application developers to package up their applications and deploy them. For PetClinic, you will be building your application image from source, leveraging OpenShift's S2I (Source to Image) capability. This allows you to quickly test the building, packaging, and deployment of your application, and gives you the option to create and use a DevOps pipeline from this workflow. It's a good way to start to understand how OpenShift Pipelines work. 1. Start with choosing Add From Git: 2. Enter https://github.com/<your-github-ID>/spring-petclinic in the Git Repo URL field. Expand the Show Advanced Git Options section, and type in main for the Git Reference . This tells OpenShift which GitHub repo and branch to pull the source code from. 3. Scroll down to the Builder section. Select the OpenJ9 tile and select openj9-11-el8 as the builder image version. As you can see OpenShift offers many different builder images to help you build images from a variety of programming languages. Your list of builder images might differ from the screen shot. For Java on Z, the recommended JVM is OpenJ9 because it has built-in s390x optimizations as well as container optimizations. 4. In the General section, put in the following entries for Application Name and Name. 5. Scroll down to the Pipelines section, and check off the box next to Add pipeline . You can also expand the Show pipeline visualization section to see a visual of the build pipeline. 6. You are almost there! You will need to configure a couple of Advanced Options. First, click on Routing in the Advanced Options section to expand the Routing options. 7. In the Routing options section, only fill out the Security options as follows. You can leave the rest alone. These options will enable only TLS access to your PetClinic application. 8. You are done with configurations of this panel. Scroll all the way down and hit the Create button which will kick off the pipeline build of your PetClinic application. In a few seconds you will see your Topology with the new application icon. Hit the little pipeline icon in the diagram below to view the build logs. Log Streaming Gotcha in the LinuxONE CC PLEASE BEWARE that if you are using the LinuxONE Community Cloud OpenShift Trial you might see lag with the log streaming. If it stops streaming, you might want to go back out to the Topology view. You can always return to the logs view, once the pipeline completes, to see the logs. 9. The pipeline will go through three tasks: 1. fetch-repository - this Pipeline task will clone your Git PetClinic repo for the build task. 2. build - this Pipeline task is the build process which itself is broken down into a few sub-steps. This is the longest task in the pipeline, and can take up to 15 minutes. The steps that it goes through are as follows: build steps STEP-GEN-ENV-FILE: this step generates the environment file to be used during the build process STEP-GENERATE: this step generates the Dockerfile that will be used to create the OCI image later on during the build step STEP-BUILD: this is the multi-step build process of creating an OCI image out of your Java application PetClinic. It will download the required Maven Java packages, compile the Java application, run through a set of 39 unit tests on the application, and finally build the application jar file and the OCI image. If the tests fail, this step will not complete. STEP-PUSH: this final step pushes the built OCI image to the OpenShift image registry. 3. deploy - this Pipeline task will deploy the newly built image as a running deployment in your project. After this, your application will be running in a pod and be accessible via a route. Below is an image of the log of a successful build task: 10. Now if you go back to the Topology view, you should see the application has been successfully deployed to OpenShift as well. From here you can click on the open URL circle, and a new browser tab should open to lead you to your PetClinic's front page.","title":"Building and Deploying PetClinic Application"},{"location":"build-and-deploy/upandrunning/#interacting-with-your-petclinic-application-and-mysql-database","text":"In this section, you will add a new owner to the Pet Clinic application, and then go into your MySQL container to see if that owner was successfully added. 1. You Pet Clinic should look something similar to this. Go to the Find Owners tab, and create a new owner. 2. Click on the Add Owner button, and add an owner of your own, for example: 3. You can then go back to Find Owners and try searching for the owner that you just added. It should come back with the search results similar to the following. 4. Now let's check the MySQL database to make sure that the new owner you just added is in there. Return to your OpenShift console, from the Topology view, click on the mysql icon. This will bring up a side panel, and then click on the mysql pod (your pod name will be different than the picture): In the pod panel, go to the Terminal tab. Now type in the following commands in your mysql terminal (copy and paste box below image): mysql -u root -h mysql -ppetclinic use petclinic ; show tables ; Let's run a SQL command now to verify that the owner that you added through the application is indeed in the database (copy and paste box below image): select * from owners ; Tip If you added a different user than alice you should see that user in place of alice on your screen. Please let the instructors know, if you don't see your owner you added listed.","title":"Interacting with Your PetClinic Application and MySQL database"},{"location":"build-and-deploy/upandrunning/#summary","text":"Congratulations, you have completed this part of the workshop! You have your virtual pet clinic up and running and have created an OpenShift Pipelines pipeline that you will build on in the next sections of the lab. You may move on to the next part by clicking Next on the bottom of the page.","title":"Summary"},{"location":"cleanup/full-cleanup/","text":"Environment Cleanup \u00b6 In this section you will clean up the different things you made during the lab in order to free up resources for other projects you intend to embark on in the community cloud as well as for other users of the environment. Pipelines Section Cleanup \u00b6 From the Pipelines section of the OpenShift UI, please complete the following cleanup tasks: Delete the trigger for your pipeline Choose to remove the trigger Click the 3 dots Choose Remove Trigger Confirm the trigger removal Choose your trigger from the dropdown menu Click Remove Delete the pipeline Click the 3 dots Choose Delete Pipeline Topology Section Cleanup \u00b6 From the Topology section of the OpenShift UI, please complete the following cleanup tasks: Delete the spring-petclinic-staging deployment and its associated resources Right-click on the icon and choose Delete Deployment Click Delete (keep box checked to also delete dependent objects of this resource) Delete mysql deployment config and its associated resources Right-click on the icon and choose Delete DeploymentConfig Click Delete (keep box checked to also delete dependent objects of this resource) Thank You for Cleaning Up! \u00b6","title":"Environment Cleanup"},{"location":"cleanup/full-cleanup/#environment-cleanup","text":"In this section you will clean up the different things you made during the lab in order to free up resources for other projects you intend to embark on in the community cloud as well as for other users of the environment.","title":"Environment Cleanup"},{"location":"cleanup/full-cleanup/#pipelines-section-cleanup","text":"From the Pipelines section of the OpenShift UI, please complete the following cleanup tasks: Delete the trigger for your pipeline Choose to remove the trigger Click the 3 dots Choose Remove Trigger Confirm the trigger removal Choose your trigger from the dropdown menu Click Remove Delete the pipeline Click the 3 dots Choose Delete Pipeline","title":"Pipelines Section Cleanup"},{"location":"cleanup/full-cleanup/#topology-section-cleanup","text":"From the Topology section of the OpenShift UI, please complete the following cleanup tasks: Delete the spring-petclinic-staging deployment and its associated resources Right-click on the icon and choose Delete Deployment Click Delete (keep box checked to also delete dependent objects of this resource) Delete mysql deployment config and its associated resources Right-click on the icon and choose Delete DeploymentConfig Click Delete (keep box checked to also delete dependent objects of this resource)","title":"Topology Section Cleanup"},{"location":"cleanup/full-cleanup/#thank-you-for-cleaning-up","text":"","title":"Thank You for Cleaning Up!"},{"location":"full-dev-pipeline/configure_overview/","text":"Configure PetClinic's Integration and Deployment Pipeline to Meet Your Organization's Needs 1 \u00b6 It's time to expand your pipeline to automate the integration and deployment process for your application (with specific configuration for your organization) using OpenShift Pipelines. This involves the following tasks: Automate PetClinic Build and Test for your Organization's Needs Automate MySQL deployment using OpenShift template Make clean image from S2I build to meet the security needs of your organization Automate PetClinic development deployment to meet your Organization's Needs 1 Manage PetClinic deployment resources using KUSTOMIZE Setup PetClinic image deployment automation with tagging based on source For the purposes of this lab, you are fulfilling the requirements of a fictional organization. These requirements could change for your specific organization but would follow a similar pattern with different specifics. \u21a9 \u21a9","title":"Configure Pipeline Overview"},{"location":"full-dev-pipeline/configure_overview/#configure-petclinics-integration-and-deployment-pipeline-to-meet-your-organizations-needs1","text":"It's time to expand your pipeline to automate the integration and deployment process for your application (with specific configuration for your organization) using OpenShift Pipelines. This involves the following tasks: Automate PetClinic Build and Test for your Organization's Needs Automate MySQL deployment using OpenShift template Make clean image from S2I build to meet the security needs of your organization Automate PetClinic development deployment to meet your Organization's Needs 1 Manage PetClinic deployment resources using KUSTOMIZE Setup PetClinic image deployment automation with tagging based on source For the purposes of this lab, you are fulfilling the requirements of a fictional organization. These requirements could change for your specific organization but would follow a similar pattern with different specifics. \u21a9 \u21a9","title":"Configure PetClinic's Integration and Deployment Pipeline to Meet Your Organization's Needs1"},{"location":"full-dev-pipeline/pipeline/","text":"Configure PetClinic Build and Test to Meet your Organization's Requirements 1 \u00b6 Now that PetClinic is up and running on your OpenShift cluster, it's time to add functionality to your pipeline to achieve basic integration and deployment when triggered. The OpenShift pipeline you created in the PetClinic Up and Running uses Tekton to run a series of tasks (each with one or more steps) to accomplish a workflow (pipeline). You will use the Pipeline Builder UI built into OpenShift to quickly and easily craft a pipeline that meets your specific needs. Why OpenShift Pipelines? Portable: OpenShift resources defined via yaml files -> portable across OpenShift clusters Low Resource Usage: Containers spin up when triggered -> resources only used when needed Configurable: Can tailor overall pipeline and individual tasks to needs of your enterprise/organization Ease of Use: Pipeline Builder UI and built-in cluster resources (i.e. ClusterTasks , ClusterTriggerBindings , etc.) enable you to easily create a pipeline and export the yaml files with minimal knowledge PetClinic Pipeline \u00b6 When you deployed the PetClinic application using the From Git option in the PetClinic Up and Running section, you chose to create a basic pipeline. You'll start with this pipeline and edit it to add new functionality for your use case. Navigate to the Pipelines tab in the Developer perspective on the left and then click the three dots to the right of the pipeline name ( spring-petclinic ) and choose Edit Pipeline . Ensure MySQL Database Deployed for each Run \u00b6 This will bring you to the Pipeline Builder UI where you can edit your pipeline. Here you will make sure the MySQL database is configured according to your specification before the build task. Add a mysql-deploy task in parallel to the git-fetch task. Why is mysql-deploy in Parallel? This ensures MySQL is in place for each PetClinic application build (which would fail without it). Click Select Task in the middle of the rectangle of the new task and choose the openshift-client task from the dropdown menu. Click on the middle of the oval of the openshift-client task to enter values for it (copy and paste boxes below image). Tip Once you add a specific task (i.e. openshift-client ), clicking on the oval of the task will enable you to edit its default values for your needs. Give the task the following parameters to ensure the MySQL database is available with the necessary configuration: Display Name mysql-deploy SCRIPT oc process openshift//mysql-ephemeral -p MYSQL_USER = petclinic -p MYSQL_PASSWORD = petclinic -p MYSQL_ROOT_PASSWORD = petclinic -p MYSQL_DATABASE = petclinic | oc apply -f - Simply Click Away Once you have entered the string into the SCRIPT section, just click away (i.e. on a regular section of the page) to get the configuration menu to go away and keep the new value(s) you just entered for the task. What is oc process doing? oc process is processing the OpenShift template for the mysql-ephemeral database with the parameters given via a series of -p arguments and finally oc apply -f - ensures that any missing components will be recreated. No help please! Make sure help is deleted from the ARGS section (it will be greyed out once deleted) or bad things will happen (i.e. the help screen will come up instead of the proper command running). Add a mysql-rollout-wait task You need to make sure that mysql is fully deployed before your build task begins. In order to achieve this, you will use the OpenShift Client again and wait for the rollout of the mysql deploymentConfig to complete after the mysql-deploy task. Add a sequential task after mysql-deploy : Select Task as openshift-client like before and then fill out the task with the following parameters (copy and paste boxes below image for changes): Display Name mysql-rollout-wait ARGS rollout status dc/mysql No help please! Make sure help is deleted from the ARGS section (it will be greyed out once deleted) or bad things will happen (i.e. the help screen will come up instead of the proper command running). What the ARGS? You may be wondering why you used the SCRIPT section in the mysql-deploy task for the entire command, but now are using the ARGS to individually list each argument of the command? Both work and so you are going through both methods here. On the one hand, the SCRIPT method is easier to copy and paste and looks the same as it would entered on the command line. On the other hand, the ARGS method adds readability to the task. Choose whichever method you prefer, though beware of input errors with the ARGS method for long commands. FYI: The equivalent SCRIPT command for the mysql-rollout-wait task is : oc rollout status dc/mysql Now your mysql-deploy and mysql-rollout tasks will have MySQL alive and well for the build task! Make Clean Image from S2I build \u00b6 The s2i-java-11 image is very convenient for making an image from source code. However, the simplicity that gives it value can make it fail at meeting the needs of many organizations by itself. In your case, you will take the artifacts from the s2i image and copy them to a new Docker image that can meet all your needs to get the best of both worlds. You'll create an optimized image starting from a compact openj9 java 11 base and employing the advanced layers feature in spring that optimizes Docker image caching with the final-Dockerfile in the ibm-wsc/spring-petclinic git repository you forked. Add Buildah task Add the buildah task as a sequential task after the build task. Configure buildah task Tip Each value that you need to configure is listed below with the value in a click-to-copy window (other values can be left alone to match the image) DISPLAY NAME: clean-image IMAGE: $(params.IMAGE_NAME)-minimal:$(params.COMMIT_SHA) DOCKERFILE: ./final-Dockerfile TLSVERIFY: false BUILD_EXTRA_ARGS: --build-arg PETCLINIC_S2I_IMAGE=$(params.IMAGE_NAME) Add GIT_MESSAGE , and COMMIT_SHA parameters to the pipeline Click Add Parameter twice ... and then fill in the parameter details for GIT_MESSAGE and COMMIT_SHA (copy and paste boxes below image) GIT_MESSAGE GIT_MESSAGE Parameter Name: GIT_MESSAGE GIT_MESSAGE Parameter Description: Git commit message if triggered by Git, otherwise it's a manual build GIT_MESSAGE Parameter Default Value This is a manual build (not triggered by Git) COMMIT_SHA COMMIT_SHA Parameter Name: COMMIT_SHA COMMIT_SHA Parameter Description: SHA of Git commit if triggered by Git, otherwise just update manual tag COMMIT_SHA Parameter Default Value: manual Tip Save parameters when done with entry by clicking on blue SAVE box before moving onto step 4. If blue SAVE box doesn't appear (is greyed out) delete extra blank parameters you may have accidentally added with the - . Add workspace to clean-image task Save current pipeline edit and switch to YAML from pipeline menu. Why are you editing yaml directly? Workspaces are more versatile than traditional PipelineResources which is why you are using them. However, as the transition to workspaces continues, the OpenShift Pipeline Builder doesn't support editing the Workspace mapping from a pipeline to a task via the Builder UI so you have to do it directly in the yaml for now. Find the clean-image-task and add the following workspace definition: workspaces : - name : source workspace : workspace Save the update Note After the save message above appears you can then proceed to Cancel back to the pipeline menu. Summary \u00b6 Your pipeline will now automatically check that your MySQL instance is configured properly and rolled out before moving on to the build stage (instead of doing this as a manual task like in the previous section of the lab). Moreover, it will curate the final PetClinic ( minimal ) image to only have the necessary components instead of a bunch of extra packages (required only for the build itself) that add bloat and potential security vulnerabilities to your image. Finally, it will tag the image to distinguish between manual builds and those triggered by a potential git push. In the next section, you will see this automation in action for your development environment. For the purposes of this lab, you are fulfilling the requirements of a fictional organization. These requirements could change for your specific organization but would follow a similar pattern with different specifics. \u21a9","title":"Configure Build and Test"},{"location":"full-dev-pipeline/pipeline/#configure-petclinic-build-and-test-to-meet-your-organizations-requirements1","text":"Now that PetClinic is up and running on your OpenShift cluster, it's time to add functionality to your pipeline to achieve basic integration and deployment when triggered. The OpenShift pipeline you created in the PetClinic Up and Running uses Tekton to run a series of tasks (each with one or more steps) to accomplish a workflow (pipeline). You will use the Pipeline Builder UI built into OpenShift to quickly and easily craft a pipeline that meets your specific needs. Why OpenShift Pipelines? Portable: OpenShift resources defined via yaml files -> portable across OpenShift clusters Low Resource Usage: Containers spin up when triggered -> resources only used when needed Configurable: Can tailor overall pipeline and individual tasks to needs of your enterprise/organization Ease of Use: Pipeline Builder UI and built-in cluster resources (i.e. ClusterTasks , ClusterTriggerBindings , etc.) enable you to easily create a pipeline and export the yaml files with minimal knowledge","title":"Configure PetClinic Build and Test to Meet your Organization's Requirements1"},{"location":"full-dev-pipeline/pipeline/#petclinic-pipeline","text":"When you deployed the PetClinic application using the From Git option in the PetClinic Up and Running section, you chose to create a basic pipeline. You'll start with this pipeline and edit it to add new functionality for your use case. Navigate to the Pipelines tab in the Developer perspective on the left and then click the three dots to the right of the pipeline name ( spring-petclinic ) and choose Edit Pipeline .","title":"PetClinic Pipeline"},{"location":"full-dev-pipeline/pipeline/#ensure-mysql-database-deployed-for-each-run","text":"This will bring you to the Pipeline Builder UI where you can edit your pipeline. Here you will make sure the MySQL database is configured according to your specification before the build task. Add a mysql-deploy task in parallel to the git-fetch task. Why is mysql-deploy in Parallel? This ensures MySQL is in place for each PetClinic application build (which would fail without it). Click Select Task in the middle of the rectangle of the new task and choose the openshift-client task from the dropdown menu. Click on the middle of the oval of the openshift-client task to enter values for it (copy and paste boxes below image). Tip Once you add a specific task (i.e. openshift-client ), clicking on the oval of the task will enable you to edit its default values for your needs. Give the task the following parameters to ensure the MySQL database is available with the necessary configuration: Display Name mysql-deploy SCRIPT oc process openshift//mysql-ephemeral -p MYSQL_USER = petclinic -p MYSQL_PASSWORD = petclinic -p MYSQL_ROOT_PASSWORD = petclinic -p MYSQL_DATABASE = petclinic | oc apply -f - Simply Click Away Once you have entered the string into the SCRIPT section, just click away (i.e. on a regular section of the page) to get the configuration menu to go away and keep the new value(s) you just entered for the task. What is oc process doing? oc process is processing the OpenShift template for the mysql-ephemeral database with the parameters given via a series of -p arguments and finally oc apply -f - ensures that any missing components will be recreated. No help please! Make sure help is deleted from the ARGS section (it will be greyed out once deleted) or bad things will happen (i.e. the help screen will come up instead of the proper command running). Add a mysql-rollout-wait task You need to make sure that mysql is fully deployed before your build task begins. In order to achieve this, you will use the OpenShift Client again and wait for the rollout of the mysql deploymentConfig to complete after the mysql-deploy task. Add a sequential task after mysql-deploy : Select Task as openshift-client like before and then fill out the task with the following parameters (copy and paste boxes below image for changes): Display Name mysql-rollout-wait ARGS rollout status dc/mysql No help please! Make sure help is deleted from the ARGS section (it will be greyed out once deleted) or bad things will happen (i.e. the help screen will come up instead of the proper command running). What the ARGS? You may be wondering why you used the SCRIPT section in the mysql-deploy task for the entire command, but now are using the ARGS to individually list each argument of the command? Both work and so you are going through both methods here. On the one hand, the SCRIPT method is easier to copy and paste and looks the same as it would entered on the command line. On the other hand, the ARGS method adds readability to the task. Choose whichever method you prefer, though beware of input errors with the ARGS method for long commands. FYI: The equivalent SCRIPT command for the mysql-rollout-wait task is : oc rollout status dc/mysql Now your mysql-deploy and mysql-rollout tasks will have MySQL alive and well for the build task!","title":"Ensure MySQL Database Deployed for each Run"},{"location":"full-dev-pipeline/pipeline/#make-clean-image-from-s2i-build","text":"The s2i-java-11 image is very convenient for making an image from source code. However, the simplicity that gives it value can make it fail at meeting the needs of many organizations by itself. In your case, you will take the artifacts from the s2i image and copy them to a new Docker image that can meet all your needs to get the best of both worlds. You'll create an optimized image starting from a compact openj9 java 11 base and employing the advanced layers feature in spring that optimizes Docker image caching with the final-Dockerfile in the ibm-wsc/spring-petclinic git repository you forked. Add Buildah task Add the buildah task as a sequential task after the build task. Configure buildah task Tip Each value that you need to configure is listed below with the value in a click-to-copy window (other values can be left alone to match the image) DISPLAY NAME: clean-image IMAGE: $(params.IMAGE_NAME)-minimal:$(params.COMMIT_SHA) DOCKERFILE: ./final-Dockerfile TLSVERIFY: false BUILD_EXTRA_ARGS: --build-arg PETCLINIC_S2I_IMAGE=$(params.IMAGE_NAME) Add GIT_MESSAGE , and COMMIT_SHA parameters to the pipeline Click Add Parameter twice ... and then fill in the parameter details for GIT_MESSAGE and COMMIT_SHA (copy and paste boxes below image) GIT_MESSAGE GIT_MESSAGE Parameter Name: GIT_MESSAGE GIT_MESSAGE Parameter Description: Git commit message if triggered by Git, otherwise it's a manual build GIT_MESSAGE Parameter Default Value This is a manual build (not triggered by Git) COMMIT_SHA COMMIT_SHA Parameter Name: COMMIT_SHA COMMIT_SHA Parameter Description: SHA of Git commit if triggered by Git, otherwise just update manual tag COMMIT_SHA Parameter Default Value: manual Tip Save parameters when done with entry by clicking on blue SAVE box before moving onto step 4. If blue SAVE box doesn't appear (is greyed out) delete extra blank parameters you may have accidentally added with the - . Add workspace to clean-image task Save current pipeline edit and switch to YAML from pipeline menu. Why are you editing yaml directly? Workspaces are more versatile than traditional PipelineResources which is why you are using them. However, as the transition to workspaces continues, the OpenShift Pipeline Builder doesn't support editing the Workspace mapping from a pipeline to a task via the Builder UI so you have to do it directly in the yaml for now. Find the clean-image-task and add the following workspace definition: workspaces : - name : source workspace : workspace Save the update Note After the save message above appears you can then proceed to Cancel back to the pipeline menu.","title":"Make Clean Image from S2I build"},{"location":"full-dev-pipeline/pipeline/#summary","text":"Your pipeline will now automatically check that your MySQL instance is configured properly and rolled out before moving on to the build stage (instead of doing this as a manual task like in the previous section of the lab). Moreover, it will curate the final PetClinic ( minimal ) image to only have the necessary components instead of a bunch of extra packages (required only for the build itself) that add bloat and potential security vulnerabilities to your image. Finally, it will tag the image to distinguish between manual builds and those triggered by a potential git push. In the next section, you will see this automation in action for your development environment. For the purposes of this lab, you are fulfilling the requirements of a fictional organization. These requirements could change for your specific organization but would follow a similar pattern with different specifics. \u21a9","title":"Summary"},{"location":"full-dev-pipeline/runpipeline/","text":"Configure PetClinic Development Deployment to Meet your Organization's Requirements 1 \u00b6 Manage resource across environments with Kustomize \u00b6 Kustomize is a tool for customizing Kubernetes resource configuration. From the documentation overview Kustomize traverses a Kubernetes manifest to add, remove or update configuration options without forking. It is available both as a standalone binary and as a native feature of kubectl. See the Introducing Kustomize Kubernetes Blog Post for a more in-depth overview of Kustomize and its purpose. As part of doing things the \"cloud native\" way you will be using Kustomize to manage resource changes across your dev and staging environments as well as injecting information from your pipeline (such as newly created image information with git commits) into your Kubernetes (OpenShift) resources. To see how you use Kustomize, see the Kustomize configuration in your GitHub code in the subdirectories of the ocp-files directory . For more information on how kubectl (and oc through kubectl) integrates Kustomize, see the kubectl documentation . Creating Custom Task for Kustomize \u00b6 Since there is no ClusterTask defined for Kustomize, you will create a custom task for this purpose. It will change into the Kustomize directory, run a Kustomize command on the directory, and then apply the files from the directory using the built-in Kustomize functionality of the oc command line tool (via kubectl's Kustomize support) Copy the kustomize task using the following definition (copy by clicking on the copy icon in the top right of the box below): apiVersion : tekton.dev/v1beta1 kind : Task metadata : name : kustomize spec : description : >- This task runs commands against the cluster where the task run is being executed. Kustomize is a tool for Kubernetes native configuration management. It introduces a template-free way to customize application configuration that simplifies the use of off-the-shelf applications. Now, built into kubectl as apply -k and oc as oc apply -k. params : - default : ocp-files description : The directory where the kustomization yaml file(s) reside in the git directory name : KUSTOMIZE_DIR type : string - default : base description : subdirectory of KUSTOMIZE_DIR used for extra configuration of current resources name : EDIT_SUDBDIR type : string - default : overlay/dev description : subdirectory of KUSTOMIZE_DIR used for specifying resources for a specific release such as dev or staging name : RELEASE_SUBDIR type : string - default : kustomize --help description : The Kustomize CLI command to run name : SCRIPT type : string steps : - image : 'docker.io/gmoney23/kustomize-s390x:v4.1.2' name : kustomize resources : limits : cpu : 200m memory : 200Mi requests : cpu : 200m memory : 200Mi workingDir : \"$(workspaces.source.path)/$(params.KUSTOMIZE_DIR)/$(params.EDIT_SUDBDIR)\" script : $(params.SCRIPT) - image : 'image-registry.openshift-image-registry.svc:5000/openshift/cli:latest' name : apply-oc-files resources : limits : cpu : 200m memory : 200Mi requests : cpu : 200m memory : 200Mi script : oc apply -k \"$(workspaces.source.path)/$(params.KUSTOMIZE_DIR)/$(params.RELEASE_SUBDIR)\" workspaces : - name : source description : The git source code Create the kustomize Task a. Click Import YAML to bring up the box where you can create Kubernetes resource definitions from yaml b. Paste the kustomize Task into the box c. Scroll down and click Create to create the kustomize Task You should now see the created kustomize Task. Navigate back to the Pipelines section of the OpenShift UI and go back to editing your pipeline. Add Kustomize Task to Pipeline \u00b6 Add a sequential task after clean-image and when you Select Task choose the kustomize task. Configure kustomize task Since your initial deploy will be for the dev environment, the only values you need to change are the Display Name and the SCRIPT (copy and paste boxes below image): Display Name kustomize-dev SCRIPT kustomize edit set image spring-petclinic = $( params.IMAGE_NAME ) -minimal: $( params.COMMIT_SHA ) Save pipeline Add workspace to kustomize-dev task Save current pipeline edit and switch to YAML from pipeline menu. Why are you editing yaml directly? Workspaces are more versatile than traditional PipelineResources which is why you are using them. However, as the transition to workspaces continues, the OpenShift Pipeline Builder doesn't support editing the Workspace mapping from a pipeline to a task via the Builder UI so you have to do it directly in the yaml for now. Find the kustomize-dev and add the following workspace definition: workspaces : - name : source workspace : workspace Save the update Note After the save message above appears you can then proceed to Cancel back to the pipeline menu. Clean Old PetClinic Instances at the Beginning of a Run \u00b6 Go back to editing your pipeline via Actions -> Edit Pipeline Add a Task named cleanup-resources sequentially at the beginning of the pipeline before fetch-repository (using the openshift-client ClusterTask). Configure the task with the following parameters (copy and paste boxes below image for changes): Display Name cleanup-resources SCRIPT oc delete deployment,cm,svc,route -l app = $( params.APP_NAME ) --ignore-not-found and an empty ARGS value. No help please! Make sure help is deleted from the ARGS section (it will be greyed out once deleted) or bad things will happen (i.e. the help screen will come up instead of the proper command running). Update Deploy Task to deploy-dev \u00b6 Click on the deploy Task at the end of the pipeline and change the following parameters to the corresponding values (copy and paste boxes below image): Display Name deploy-dev Script echo \" $( params.GIT_MESSAGE ) \" && oc $@ Last Arg From deploy/$(params.APP_NAME) to: deploy/spring-petclinic-dev Save your pipeline! Run the Updated Pipeline \u00b6 Go to Actions -> Start in the right hand corner of the pipeline menu Manually trigger a PipelineRun by accepting the default values and clicking on Start . Persistent Volume Claim Note Please select a PersistentVolumeClaim if it is not already filled out for you to complete your pipeline. If it is already filled out for you then jump right to starting the pipeline. Watch the results of your build pipeline run. It should complete successfully as in the pictures below. Pipeline Run Success View Perspective: Pipeline Run Details View In the pipeline run Details view, you can see the pipeline run succeeded with all tasks having a green check mark. Additionally, the pipeline run in the above screenshot was Triggered By a user versus an automated source such as an event listener watching for a GitHub push... Pipeline Run Success Logs Perspective: Pipeline Run Logs View From the pipeline run Logs view you can see that the pipeline run tasks all have green check marks and that this was a manual build (from the message in the log output of the final [ deploy-dev ] task). Summary \u00b6 Congratulations! You successfully deployed your PetClinic application to your development environment with automated checks and configuration to meet your needs. This means that whenever your pipeline is triggered it will automatically spin up resources to build, test and deploy your application according to the specification you need to meet for your organization 1 . For the purposes of this lab, you are fulfilling the requirements of a fictional organization. These requirements could change for your specific organization but would follow a similar pattern with different specifics. \u21a9 \u21a9","title":"Configure Development Deployment"},{"location":"full-dev-pipeline/runpipeline/#configure-petclinic-development-deployment-to-meet-your-organizations-requirements1","text":"","title":"Configure PetClinic Development Deployment to Meet your Organization's Requirements1"},{"location":"full-dev-pipeline/runpipeline/#manage-resource-across-environments-with-kustomize","text":"Kustomize is a tool for customizing Kubernetes resource configuration. From the documentation overview Kustomize traverses a Kubernetes manifest to add, remove or update configuration options without forking. It is available both as a standalone binary and as a native feature of kubectl. See the Introducing Kustomize Kubernetes Blog Post for a more in-depth overview of Kustomize and its purpose. As part of doing things the \"cloud native\" way you will be using Kustomize to manage resource changes across your dev and staging environments as well as injecting information from your pipeline (such as newly created image information with git commits) into your Kubernetes (OpenShift) resources. To see how you use Kustomize, see the Kustomize configuration in your GitHub code in the subdirectories of the ocp-files directory . For more information on how kubectl (and oc through kubectl) integrates Kustomize, see the kubectl documentation .","title":"Manage resource across environments with Kustomize"},{"location":"full-dev-pipeline/runpipeline/#creating-custom-task-for-kustomize","text":"Since there is no ClusterTask defined for Kustomize, you will create a custom task for this purpose. It will change into the Kustomize directory, run a Kustomize command on the directory, and then apply the files from the directory using the built-in Kustomize functionality of the oc command line tool (via kubectl's Kustomize support) Copy the kustomize task using the following definition (copy by clicking on the copy icon in the top right of the box below): apiVersion : tekton.dev/v1beta1 kind : Task metadata : name : kustomize spec : description : >- This task runs commands against the cluster where the task run is being executed. Kustomize is a tool for Kubernetes native configuration management. It introduces a template-free way to customize application configuration that simplifies the use of off-the-shelf applications. Now, built into kubectl as apply -k and oc as oc apply -k. params : - default : ocp-files description : The directory where the kustomization yaml file(s) reside in the git directory name : KUSTOMIZE_DIR type : string - default : base description : subdirectory of KUSTOMIZE_DIR used for extra configuration of current resources name : EDIT_SUDBDIR type : string - default : overlay/dev description : subdirectory of KUSTOMIZE_DIR used for specifying resources for a specific release such as dev or staging name : RELEASE_SUBDIR type : string - default : kustomize --help description : The Kustomize CLI command to run name : SCRIPT type : string steps : - image : 'docker.io/gmoney23/kustomize-s390x:v4.1.2' name : kustomize resources : limits : cpu : 200m memory : 200Mi requests : cpu : 200m memory : 200Mi workingDir : \"$(workspaces.source.path)/$(params.KUSTOMIZE_DIR)/$(params.EDIT_SUDBDIR)\" script : $(params.SCRIPT) - image : 'image-registry.openshift-image-registry.svc:5000/openshift/cli:latest' name : apply-oc-files resources : limits : cpu : 200m memory : 200Mi requests : cpu : 200m memory : 200Mi script : oc apply -k \"$(workspaces.source.path)/$(params.KUSTOMIZE_DIR)/$(params.RELEASE_SUBDIR)\" workspaces : - name : source description : The git source code Create the kustomize Task a. Click Import YAML to bring up the box where you can create Kubernetes resource definitions from yaml b. Paste the kustomize Task into the box c. Scroll down and click Create to create the kustomize Task You should now see the created kustomize Task. Navigate back to the Pipelines section of the OpenShift UI and go back to editing your pipeline.","title":"Creating Custom Task for Kustomize"},{"location":"full-dev-pipeline/runpipeline/#add-kustomize-task-to-pipeline","text":"Add a sequential task after clean-image and when you Select Task choose the kustomize task. Configure kustomize task Since your initial deploy will be for the dev environment, the only values you need to change are the Display Name and the SCRIPT (copy and paste boxes below image): Display Name kustomize-dev SCRIPT kustomize edit set image spring-petclinic = $( params.IMAGE_NAME ) -minimal: $( params.COMMIT_SHA ) Save pipeline Add workspace to kustomize-dev task Save current pipeline edit and switch to YAML from pipeline menu. Why are you editing yaml directly? Workspaces are more versatile than traditional PipelineResources which is why you are using them. However, as the transition to workspaces continues, the OpenShift Pipeline Builder doesn't support editing the Workspace mapping from a pipeline to a task via the Builder UI so you have to do it directly in the yaml for now. Find the kustomize-dev and add the following workspace definition: workspaces : - name : source workspace : workspace Save the update Note After the save message above appears you can then proceed to Cancel back to the pipeline menu.","title":"Add Kustomize Task to Pipeline"},{"location":"full-dev-pipeline/runpipeline/#clean-old-petclinic-instances-at-the-beginning-of-a-run","text":"Go back to editing your pipeline via Actions -> Edit Pipeline Add a Task named cleanup-resources sequentially at the beginning of the pipeline before fetch-repository (using the openshift-client ClusterTask). Configure the task with the following parameters (copy and paste boxes below image for changes): Display Name cleanup-resources SCRIPT oc delete deployment,cm,svc,route -l app = $( params.APP_NAME ) --ignore-not-found and an empty ARGS value. No help please! Make sure help is deleted from the ARGS section (it will be greyed out once deleted) or bad things will happen (i.e. the help screen will come up instead of the proper command running).","title":"Clean Old PetClinic Instances at the Beginning of a Run"},{"location":"full-dev-pipeline/runpipeline/#update-deploy-task-to-deploy-dev","text":"Click on the deploy Task at the end of the pipeline and change the following parameters to the corresponding values (copy and paste boxes below image): Display Name deploy-dev Script echo \" $( params.GIT_MESSAGE ) \" && oc $@ Last Arg From deploy/$(params.APP_NAME) to: deploy/spring-petclinic-dev Save your pipeline!","title":"Update Deploy Task to deploy-dev"},{"location":"full-dev-pipeline/runpipeline/#run-the-updated-pipeline","text":"Go to Actions -> Start in the right hand corner of the pipeline menu Manually trigger a PipelineRun by accepting the default values and clicking on Start . Persistent Volume Claim Note Please select a PersistentVolumeClaim if it is not already filled out for you to complete your pipeline. If it is already filled out for you then jump right to starting the pipeline. Watch the results of your build pipeline run. It should complete successfully as in the pictures below. Pipeline Run Success View Perspective: Pipeline Run Details View In the pipeline run Details view, you can see the pipeline run succeeded with all tasks having a green check mark. Additionally, the pipeline run in the above screenshot was Triggered By a user versus an automated source such as an event listener watching for a GitHub push... Pipeline Run Success Logs Perspective: Pipeline Run Logs View From the pipeline run Logs view you can see that the pipeline run tasks all have green check marks and that this was a manual build (from the message in the log output of the final [ deploy-dev ] task).","title":"Run the Updated Pipeline"},{"location":"full-dev-pipeline/runpipeline/#summary","text":"Congratulations! You successfully deployed your PetClinic application to your development environment with automated checks and configuration to meet your needs. This means that whenever your pipeline is triggered it will automatically spin up resources to build, test and deploy your application according to the specification you need to meet for your organization 1 . For the purposes of this lab, you are fulfilling the requirements of a fictional organization. These requirements could change for your specific organization but would follow a similar pattern with different specifics. \u21a9 \u21a9","title":"Summary"}]}